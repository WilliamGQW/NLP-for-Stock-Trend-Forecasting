{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gw8_Z-TJ87K",
        "outputId": "63695074-02bb-4f3f-84bd-d0914b4642d6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRuMAlOOKGDF",
        "outputId": "316e17b4-ab49-447b-f502-a80b666dade8"
      },
      "outputs": [],
      "source": [
        "%cd '/content/drive/MyDrive/csci544-project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K5bT3MnT4to",
        "outputId": "f76cbb40-e220-4c2a-bcbb-9f8ee0adfc5f"
      },
      "outputs": [],
      "source": [
        "# import necessary packages\n",
        "# %tensorflow_version 2.x\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "from numpy import newaxis\n",
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM, GRU\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "from math import pi,sqrt,exp,pow,log\n",
        "from numpy.linalg import det, inv\n",
        "from abc import ABCMeta, abstractmethod\n",
        "from sklearn import cluster\n",
        "\n",
        "import statsmodels.api as sm \n",
        "import scipy.stats as scs\n",
        "import scipy.optimize as sco\n",
        "import scipy.interpolate as sci\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_curve, auc, mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li4Rosf9yaOU"
      },
      "source": [
        "# Level 0 - Second Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "_kZo37XWl-j-",
        "outputId": "00e7d71e-b209-432b-95d1-3439efb8a4cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4adb0ee0-384f-48e1-9f1e-83a1d5a9c53b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>CLI</th>\n",
              "      <th>BCI</th>\n",
              "      <th>CCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>2018/5/25</td>\n",
              "      <td>0.030290</td>\n",
              "      <td>0.047433</td>\n",
              "      <td>0.011550</td>\n",
              "      <td>-0.025190</td>\n",
              "      <td>2721.330078</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>2018/5/29</td>\n",
              "      <td>-0.052796</td>\n",
              "      <td>0.070442</td>\n",
              "      <td>-0.025721</td>\n",
              "      <td>-0.035568</td>\n",
              "      <td>2689.860107</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>2018/5/30</td>\n",
              "      <td>-0.017367</td>\n",
              "      <td>0.038119</td>\n",
              "      <td>-0.076965</td>\n",
              "      <td>-0.063177</td>\n",
              "      <td>2724.010010</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>2018/5/31</td>\n",
              "      <td>-0.018636</td>\n",
              "      <td>0.057371</td>\n",
              "      <td>-0.064138</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>2705.270020</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>2018/6/1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.061150</td>\n",
              "      <td>0.361200</td>\n",
              "      <td>-0.004489</td>\n",
              "      <td>2734.620117</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>1.3308</td>\n",
              "      <td>1.4417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4adb0ee0-384f-48e1-9f1e-83a1d5a9c53b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4adb0ee0-384f-48e1-9f1e-83a1d5a9c53b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4adb0ee0-384f-48e1-9f1e-83a1d5a9c53b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          date  wsj_mean_compound  cnbc_mean_compound  fortune_mean_compound  \\\n",
              "116  2018/5/25           0.030290            0.047433               0.011550   \n",
              "117  2018/5/29          -0.052796            0.070442              -0.025721   \n",
              "118  2018/5/30          -0.017367            0.038119              -0.076965   \n",
              "119  2018/5/31          -0.018636            0.057371              -0.064138   \n",
              "120   2018/6/1           0.000000           -0.061150               0.361200   \n",
              "\n",
              "     reuters_mean_compound    Adj Close     CLI     BCI     CCI  \n",
              "116              -0.025190  2721.330078  0.7426  1.2187  1.5006  \n",
              "117              -0.035568  2689.860107  0.7426  1.2187  1.5006  \n",
              "118              -0.063177  2724.010010  0.7426  1.2187  1.5006  \n",
              "119              -0.025489  2705.270020  0.7426  1.2187  1.5006  \n",
              "120              -0.004489  2734.620117  0.7163  1.3308  1.4417  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read data - local and colab\n",
        "# df1 = pd.read_csv(\"/Users/nathanli/masterProject/env/data/DP-LSTM_DATA/source_price.csv\")\n",
        "url = './data/source_price_sentiment_oecd.csv'\n",
        "df2= pd.read_csv(url)\n",
        "df2.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "dCX0Tbuzl-eU",
        "outputId": "c4ed28ee-0681-430c-a705-27b662dbf170"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d342a1b2-044d-4f27-b53f-f55c7af3ce10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>CLI</th>\n",
              "      <th>BCI</th>\n",
              "      <th>CCI</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017/12/7</th>\n",
              "      <td>0.296000</td>\n",
              "      <td>-0.136600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2636.979980</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/12/8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.242300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2651.500000</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/12/11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2659.989990</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/12/12</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2664.110107</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/12/13</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2662.850098</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/25</th>\n",
              "      <td>0.030290</td>\n",
              "      <td>0.047433</td>\n",
              "      <td>0.011550</td>\n",
              "      <td>-0.025190</td>\n",
              "      <td>2721.330078</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/29</th>\n",
              "      <td>-0.052796</td>\n",
              "      <td>0.070442</td>\n",
              "      <td>-0.025721</td>\n",
              "      <td>-0.035568</td>\n",
              "      <td>2689.860107</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/30</th>\n",
              "      <td>-0.017367</td>\n",
              "      <td>0.038119</td>\n",
              "      <td>-0.076965</td>\n",
              "      <td>-0.063177</td>\n",
              "      <td>2724.010010</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/31</th>\n",
              "      <td>-0.018636</td>\n",
              "      <td>0.057371</td>\n",
              "      <td>-0.064138</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>2705.270020</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/6/1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.061150</td>\n",
              "      <td>0.361200</td>\n",
              "      <td>-0.004489</td>\n",
              "      <td>2734.620117</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>1.3308</td>\n",
              "      <td>1.4417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d342a1b2-044d-4f27-b53f-f55c7af3ce10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d342a1b2-044d-4f27-b53f-f55c7af3ce10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d342a1b2-044d-4f27-b53f-f55c7af3ce10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            wsj_mean_compound  cnbc_mean_compound  fortune_mean_compound  \\\n",
              "date                                                                       \n",
              "2017/12/7            0.296000           -0.136600               0.000000   \n",
              "2017/12/8            0.000000            0.000000              -0.242300   \n",
              "2017/12/11           0.000000            0.000000               0.000000   \n",
              "2017/12/12           0.000000            0.000000               0.000000   \n",
              "2017/12/13           0.000000            0.000000               0.000000   \n",
              "...                       ...                 ...                    ...   \n",
              "2018/5/25            0.030290            0.047433               0.011550   \n",
              "2018/5/29           -0.052796            0.070442              -0.025721   \n",
              "2018/5/30           -0.017367            0.038119              -0.076965   \n",
              "2018/5/31           -0.018636            0.057371              -0.064138   \n",
              "2018/6/1             0.000000           -0.061150               0.361200   \n",
              "\n",
              "            reuters_mean_compound    Adj Close     CLI     BCI     CCI  \n",
              "date                                                                    \n",
              "2017/12/7                0.000000  2636.979980  0.4484  1.3452  1.3407  \n",
              "2017/12/8                0.000000  2651.500000  0.4484  1.3452  1.3407  \n",
              "2017/12/11               0.000000  2659.989990  0.4484  1.3452  1.3407  \n",
              "2017/12/12               0.000000  2664.110107  0.4484  1.3452  1.3407  \n",
              "2017/12/13               0.000000  2662.850098  0.4484  1.3452  1.3407  \n",
              "...                           ...          ...     ...     ...     ...  \n",
              "2018/5/25               -0.025190  2721.330078  0.7426  1.2187  1.5006  \n",
              "2018/5/29               -0.035568  2689.860107  0.7426  1.2187  1.5006  \n",
              "2018/5/30               -0.063177  2724.010010  0.7426  1.2187  1.5006  \n",
              "2018/5/31               -0.025489  2705.270020  0.7426  1.2187  1.5006  \n",
              "2018/6/1                -0.004489  2734.620117  0.7163  1.3308  1.4417  \n",
              "\n",
              "[121 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set index to date\n",
        "df2.index = df2.date\n",
        "df2.drop('date', axis=1, inplace=True)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVnJG5oEl-ZM",
        "outputId": "870be4ff-0881-4461-de5f-dad56a900328"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2636.97998 , 2651.5     , 2659.98999 , 2664.110107, 2662.850098,\n",
              "       2652.01001 , 2675.810059, 2690.159912, 2681.469971, 2679.25    ,\n",
              "       2684.570068, 2683.340088, 2680.5     , 2682.620117, 2687.540039,\n",
              "       2673.610107, 2695.810059, 2713.060059, 2723.98999 , 2743.149902,\n",
              "       2747.709961, 2751.290039, 2748.22998 , 2767.560059, 2786.23999 ,\n",
              "       2776.419922, 2802.560059, 2798.030029, 2810.300049, 2832.969971,\n",
              "       2839.129883, 2837.540039, 2839.25    , 2872.870117, 2853.530029,\n",
              "       2822.429932, 2823.810059, 2821.97998 , 2762.129883, 2648.939941,\n",
              "       2695.139893, 2681.659912, 2581.      , 2619.550049, 2656.      ,\n",
              "       2662.939941, 2698.629883, 2731.199951, 2732.219971, 2716.26001 ,\n",
              "       2701.330078, 2703.959961, 2747.300049, 2779.600098, 2744.280029,\n",
              "       2713.830078, 2677.669922, 2691.25    , 2720.939941, 2728.120117,\n",
              "       2726.800049, 2738.969971, 2786.570068, 2783.02002 , 2765.310059,\n",
              "       2749.47998 , 2747.330078, 2752.01001 , 2712.919922, 2716.939941,\n",
              "       2711.929932, 2643.689941, 2588.26001 , 2658.550049, 2612.620117,\n",
              "       2605.      , 2640.870117, 2581.879883, 2614.449951, 2644.689941,\n",
              "       2662.840088, 2604.469971, 2613.159912, 2656.870117, 2642.189941,\n",
              "       2663.98999 , 2656.300049, 2677.840088, 2706.389893, 2708.639893,\n",
              "       2693.129883, 2670.139893, 2670.290039, 2634.560059, 2639.399902,\n",
              "       2666.939941, 2669.909912, 2648.050049, 2654.800049, 2635.669922,\n",
              "       2629.72998 , 2663.419922, 2672.629883, 2671.919922, 2697.790039,\n",
              "       2723.070068, 2727.719971, 2730.129883, 2711.449951, 2722.459961,\n",
              "       2720.129883, 2712.969971, 2733.01001 , 2724.439941, 2733.290039,\n",
              "       2727.76001 , 2721.330078, 2689.860107, 2724.01001 , 2705.27002 ,\n",
              "       2734.620117])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adjust_close=df2['Adj Close'].values\n",
        "CLI=df2['CLI'].values\n",
        "BCI=df2['BCI'].values\n",
        "CCI=df2['CCI'].values\n",
        "adjust_close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b1jm2L7Ll-UX"
      },
      "outputs": [],
      "source": [
        "# nomalize adjust close stock price\n",
        "scaler = MinMaxScaler()\n",
        "scaled_adjust_close=scaler.fit_transform(adjust_close.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-A0RHdel-Sj",
        "outputId": "02227f96-4244-42a0-eb70-ee60c36c0daa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.19179757],\n",
              "       [0.2415458 ],\n",
              "       [0.27063404],\n",
              "       [0.28475031],\n",
              "       [0.28043329],\n",
              "       [0.24329318],\n",
              "       [0.32483647],\n",
              "       [0.37400167],\n",
              "       [0.34422836],\n",
              "       [0.33662233],\n",
              "       [0.35484985],\n",
              "       [0.35063572],\n",
              "       [0.34090506],\n",
              "       [0.34816897],\n",
              "       [0.36502551],\n",
              "       [0.31729904],\n",
              "       [0.3933601 ],\n",
              "       [0.45246173],\n",
              "       [0.48990966],\n",
              "       [0.555555  ],\n",
              "       [0.57117859],\n",
              "       [0.58344458],\n",
              "       [0.57296027],\n",
              "       [0.63918863],\n",
              "       [0.70318946],\n",
              "       [0.66954412],\n",
              "       [0.75910498],\n",
              "       [0.74358427],\n",
              "       [0.78562359],\n",
              "       [0.86329486],\n",
              "       [0.88439983],\n",
              "       [0.87895274],\n",
              "       [0.88481138],\n",
              "       [1.        ],\n",
              "       [0.93373735],\n",
              "       [0.82718277],\n",
              "       [0.83191134],\n",
              "       [0.82564115],\n",
              "       [0.62058386],\n",
              "       [0.23277457],\n",
              "       [0.39106399],\n",
              "       [0.34487913],\n",
              "       [0.        ],\n",
              "       [0.13207947],\n",
              "       [0.25696361],\n",
              "       [0.28074111],\n",
              "       [0.40302133],\n",
              "       [0.5146123 ],\n",
              "       [0.51810707],\n",
              "       [0.46342535],\n",
              "       [0.41227269],\n",
              "       [0.42128315],\n",
              "       [0.56977415],\n",
              "       [0.68043998],\n",
              "       [0.55942702],\n",
              "       [0.45509996],\n",
              "       [0.3312087 ],\n",
              "       [0.37773651],\n",
              "       [0.47945964],\n",
              "       [0.50406023],\n",
              "       [0.49953743],\n",
              "       [0.54123379],\n",
              "       [0.70432037],\n",
              "       [0.69215726],\n",
              "       [0.63147972],\n",
              "       [0.57724299],\n",
              "       [0.56987704],\n",
              "       [0.58591134],\n",
              "       [0.4519816 ],\n",
              "       [0.46575491],\n",
              "       [0.44858971],\n",
              "       [0.21478712],\n",
              "       [0.02487411],\n",
              "       [0.26570054],\n",
              "       [0.10833626],\n",
              "       [0.08222836],\n",
              "       [0.20512589],\n",
              "       [0.00301464],\n",
              "       [0.1146056 ],\n",
              "       [0.2182133 ],\n",
              "       [0.280399  ],\n",
              "       [0.08041238],\n",
              "       [0.1101857 ],\n",
              "       [0.25994479],\n",
              "       [0.20964784],\n",
              "       [0.28433877],\n",
              "       [0.25799164],\n",
              "       [0.33179172],\n",
              "       [0.42960853],\n",
              "       [0.43731744],\n",
              "       [0.38417733],\n",
              "       [0.30540945],\n",
              "       [0.30592388],\n",
              "       [0.18350648],\n",
              "       [0.20008866],\n",
              "       [0.29444584],\n",
              "       [0.3046215 ],\n",
              "       [0.22972564],\n",
              "       [0.25285236],\n",
              "       [0.18730908],\n",
              "       [0.16695776],\n",
              "       [0.28238561],\n",
              "       [0.31394061],\n",
              "       [0.31150816],\n",
              "       [0.40014387],\n",
              "       [0.48675784],\n",
              "       [0.50268925],\n",
              "       [0.51094605],\n",
              "       [0.44694521],\n",
              "       [0.4846675 ],\n",
              "       [0.47668423],\n",
              "       [0.45215308],\n",
              "       [0.52081389],\n",
              "       [0.49145127],\n",
              "       [0.52177332],\n",
              "       [0.50282643],\n",
              "       [0.48079632],\n",
              "       [0.37297449],\n",
              "       [0.48997825],\n",
              "       [0.42577165],\n",
              "       [0.52633041]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if adjust close is scaled\n",
        "scaled_adjust_close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "VoRN3OYkl-MI",
        "outputId": "afcbf0aa-a7f5-4de7-ef86-2ee0f5f63b58"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e317c42e-f861-47ae-aad2-e6508952d6a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>CLI</th>\n",
              "      <th>BCI</th>\n",
              "      <th>CCI</th>\n",
              "      <th>scaled_adj_close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018/5/25</th>\n",
              "      <td>0.030290</td>\n",
              "      <td>0.047433</td>\n",
              "      <td>0.011550</td>\n",
              "      <td>-0.025190</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "      <td>0.480796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/29</th>\n",
              "      <td>-0.052796</td>\n",
              "      <td>0.070442</td>\n",
              "      <td>-0.025721</td>\n",
              "      <td>-0.035568</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "      <td>0.372974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/30</th>\n",
              "      <td>-0.017367</td>\n",
              "      <td>0.038119</td>\n",
              "      <td>-0.076965</td>\n",
              "      <td>-0.063177</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "      <td>0.489978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/31</th>\n",
              "      <td>-0.018636</td>\n",
              "      <td>0.057371</td>\n",
              "      <td>-0.064138</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "      <td>0.425772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/6/1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.061150</td>\n",
              "      <td>0.361200</td>\n",
              "      <td>-0.004489</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>1.3308</td>\n",
              "      <td>1.4417</td>\n",
              "      <td>0.526330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e317c42e-f861-47ae-aad2-e6508952d6a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e317c42e-f861-47ae-aad2-e6508952d6a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e317c42e-f861-47ae-aad2-e6508952d6a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           wsj_mean_compound  cnbc_mean_compound  fortune_mean_compound  \\\n",
              "date                                                                      \n",
              "2018/5/25           0.030290            0.047433               0.011550   \n",
              "2018/5/29          -0.052796            0.070442              -0.025721   \n",
              "2018/5/30          -0.017367            0.038119              -0.076965   \n",
              "2018/5/31          -0.018636            0.057371              -0.064138   \n",
              "2018/6/1            0.000000           -0.061150               0.361200   \n",
              "\n",
              "           reuters_mean_compound     CLI     BCI     CCI  scaled_adj_close  \n",
              "date                                                                        \n",
              "2018/5/25              -0.025190  0.7426  1.2187  1.5006          0.480796  \n",
              "2018/5/29              -0.035568  0.7426  1.2187  1.5006          0.372974  \n",
              "2018/5/30              -0.063177  0.7426  1.2187  1.5006          0.489978  \n",
              "2018/5/31              -0.025489  0.7426  1.2187  1.5006          0.425772  \n",
              "2018/6/1               -0.004489  0.7163  1.3308  1.4417          0.526330  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data=df2.drop(['Adj Close'],axis=1)\n",
        "\n",
        "new_data['scaled_adj_close'] = scaled_adjust_close\n",
        "\n",
        "new_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO_UuyrIl-Jc",
        "outputId": "a638cf9b-b553-4d4e-e320-abe1096f0f69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "wsj_mean_compound        float64\n",
              "cnbc_mean_compound       float64\n",
              "fortune_mean_compound    float64\n",
              "reuters_mean_compound    float64\n",
              "CLI                      float64\n",
              "BCI                      float64\n",
              "CCI                      float64\n",
              "scaled_adj_close         float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xEh2WY1y_7j",
        "outputId": "ba2d09c3-38dc-4664-940d-0158d6451a3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 8)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8kf1DwDPzADP"
      },
      "outputs": [],
      "source": [
        "# split data into train and test\n",
        "# train 85% and test 15%\n",
        "train_validation_data, test_data= train_test_split(new_data, train_size=0.85, test_size=0.15,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "ZtLe6CTOzAK-",
        "outputId": "42d1d786-2f9e-4ee2-b6f6-29c3a65e6ae5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c7862e2a-3bd6-4e95-85fb-4fc0362c8a05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>CLI</th>\n",
              "      <th>BCI</th>\n",
              "      <th>CCI</th>\n",
              "      <th>scaled_adj_close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018/4/30</th>\n",
              "      <td>-0.009474</td>\n",
              "      <td>0.064056</td>\n",
              "      <td>0.021328</td>\n",
              "      <td>0.066076</td>\n",
              "      <td>0.7434</td>\n",
              "      <td>1.1734</td>\n",
              "      <td>1.5880</td>\n",
              "      <td>0.229726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/1</th>\n",
              "      <td>-0.044864</td>\n",
              "      <td>0.084246</td>\n",
              "      <td>-0.013291</td>\n",
              "      <td>0.068956</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "      <td>0.252852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/2</th>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.088057</td>\n",
              "      <td>0.043339</td>\n",
              "      <td>0.053706</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "      <td>0.187309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/3</th>\n",
              "      <td>0.017188</td>\n",
              "      <td>0.066461</td>\n",
              "      <td>0.063148</td>\n",
              "      <td>0.068072</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "      <td>0.166958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018/5/4</th>\n",
              "      <td>-0.001986</td>\n",
              "      <td>0.073777</td>\n",
              "      <td>-0.021277</td>\n",
              "      <td>0.062085</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "      <td>0.282386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7862e2a-3bd6-4e95-85fb-4fc0362c8a05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7862e2a-3bd6-4e95-85fb-4fc0362c8a05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7862e2a-3bd6-4e95-85fb-4fc0362c8a05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           wsj_mean_compound  cnbc_mean_compound  fortune_mean_compound  \\\n",
              "date                                                                      \n",
              "2018/4/30          -0.009474            0.064056               0.021328   \n",
              "2018/5/1           -0.044864            0.084246              -0.013291   \n",
              "2018/5/2            0.000608            0.088057               0.043339   \n",
              "2018/5/3            0.017188            0.066461               0.063148   \n",
              "2018/5/4           -0.001986            0.073777              -0.021277   \n",
              "\n",
              "           reuters_mean_compound     CLI     BCI     CCI  scaled_adj_close  \n",
              "date                                                                        \n",
              "2018/4/30               0.066076  0.7434  1.1734  1.5880          0.229726  \n",
              "2018/5/1                0.068956  0.7426  1.2187  1.5006          0.252852  \n",
              "2018/5/2                0.053706  0.7426  1.2187  1.5006          0.187309  \n",
              "2018/5/3                0.068072  0.7426  1.2187  1.5006          0.166958  \n",
              "2018/5/4                0.062085  0.7426  1.2187  1.5006          0.282386  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_validation_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5shD0u8zARi",
        "outputId": "ab37e771-8992-4103-fb72-24e3f5d7a9cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(102, 8)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_validation_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7DF00uPzAYl",
        "outputId": "ab961a9e-8a1d-4e67-979e-6d3f8af3d1a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data shape:  (83, 8)\n",
            "validation data shape:  (19, 8)\n",
            "test data shape:  (19, 8)\n"
          ]
        }
      ],
      "source": [
        "validation_data =train_validation_data[83:]\n",
        "train_data=train_validation_data[:83]\n",
        "\n",
        "print(\"train data shape: \", train_data.shape)\n",
        "print(\"validation data shape: \", validation_data.shape)\n",
        "print(\"test data shape: \", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pUyc2PWvzgEt"
      },
      "outputs": [],
      "source": [
        "# configs\n",
        "look_back = 10\n",
        "forward_days = 1\n",
        "NUM_NEURONS=50\n",
        "EPOCHES=100\n",
        "BATCH_SIZE=32\n",
        "DROUP_OUT=0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vGNUGlwAzgKX"
      },
      "outputs": [],
      "source": [
        "#Get the data and splits in input X and output Y, by spliting in `n` past days as input X \n",
        "#and `m` coming days as Y.\n",
        "def processData(data, look_back, forward_days,jump=1):\n",
        "    A,B = [],[]\n",
        "    for i in range(0,len(data) -look_back, jump):\n",
        "        A.append(data[i:(i+look_back)])\n",
        "        B.append(data[(i+look_back):(i+look_back+forward_days)])\n",
        "    return np.array(A), np.array(B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GlguqaLLzgSE"
      },
      "outputs": [],
      "source": [
        "m_training_data = train_data.to_numpy()\n",
        "m_validation_data = validation_data.to_numpy()\n",
        "m_test_data = test_data.to_numpy()\n",
        "\n",
        "X_train,Y_train = processData(m_training_data,look_back,forward_days)\n",
        "X_validation,Y_validation = processData(m_validation_data,look_back,forward_days)\n",
        "X_test,Y_test = processData(m_test_data,look_back,forward_days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCqJlq6HzgVx",
        "outputId": "d7cb4a02-8e5e-4b53-9656-2565cf57e452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is y_train shape (73,)\n",
            "This is y_validation shape (9,)\n",
            "This is y_test shape (9,)\n"
          ]
        }
      ],
      "source": [
        "Y_train=Y_train[:,0,-1]\n",
        "Y_validation=Y_validation[:,0,-1]\n",
        "Y_test=Y_test[:,0,-1]\n",
        "\n",
        "print(\"This is y_train shape\",Y_train.shape)\n",
        "print(\"This is y_validation shape\",Y_validation.shape)\n",
        "print(\"This is y_test shape\",Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCKRmFuh-QIV"
      },
      "source": [
        "# LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcEen7hea_yL",
        "outputId": "f9f6ab13-02c1-4ff9-ee8d-dfaa33a9013c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 73 samples\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 1s 18ms/sample - loss: 0.2610\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 942us/sample - loss: 0.1405\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 940us/sample - loss: 0.0727\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 996us/sample - loss: 0.0847\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0578\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 940us/sample - loss: 0.0706\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 891us/sample - loss: 0.0663\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 985us/sample - loss: 0.0645\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 917us/sample - loss: 0.0610\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 964us/sample - loss: 0.0647\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 967us/sample - loss: 0.0563\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0571\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 910us/sample - loss: 0.0582\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 953us/sample - loss: 0.0536\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 933us/sample - loss: 0.0602\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0634\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0604\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0592\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0524\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0553\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0588\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0512\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0580\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 930us/sample - loss: 0.0513\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 970us/sample - loss: 0.0466\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0500\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0455\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0504\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0509\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0450\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0425\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0483\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0416\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0509\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0534\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 946us/sample - loss: 0.0443\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0430\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 979us/sample - loss: 0.0482\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 975us/sample - loss: 0.0450\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 947us/sample - loss: 0.0437\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 974us/sample - loss: 0.0394\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 994us/sample - loss: 0.0449\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 907us/sample - loss: 0.0352\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 909us/sample - loss: 0.0402\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 948us/sample - loss: 0.0420\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 906us/sample - loss: 0.0338\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 979us/sample - loss: 0.0372\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 907us/sample - loss: 0.0384\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0419\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0401\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0413\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0410\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0390\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0422\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0370\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0441\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0343\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0400\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0364\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0339\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 972us/sample - loss: 0.0372\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 945us/sample - loss: 0.0342\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 925us/sample - loss: 0.0313\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 914us/sample - loss: 0.0326\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0325\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 996us/sample - loss: 0.0308\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 908us/sample - loss: 0.0292\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 972us/sample - loss: 0.0293\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0254\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 917us/sample - loss: 0.0266\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 875us/sample - loss: 0.0278\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 881us/sample - loss: 0.0270\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 956us/sample - loss: 0.0225\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 978us/sample - loss: 0.0248\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0230\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 994us/sample - loss: 0.0244\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 987us/sample - loss: 0.0238\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 956us/sample - loss: 0.0192\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0316\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 929us/sample - loss: 0.0325\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0218\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0314\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0209\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0271\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 886us/sample - loss: 0.0228\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 955us/sample - loss: 0.0187\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 879us/sample - loss: 0.0163\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 919us/sample - loss: 0.0178\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 988us/sample - loss: 0.0191\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 910us/sample - loss: 0.0159\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 977us/sample - loss: 0.0176\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0210\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0154\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 915us/sample - loss: 0.0177\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 902us/sample - loss: 0.0167\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 944us/sample - loss: 0.0160\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 913us/sample - loss: 0.0200\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 903us/sample - loss: 0.0151\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 950us/sample - loss: 0.0145\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 919us/sample - loss: 0.0164\n"
          ]
        }
      ],
      "source": [
        "# build LSTM model\n",
        "model1 = Sequential()\n",
        "# first layer\n",
        "model1.add(LSTM(units=NUM_NEURONS, return_sequences = True, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model1.add(Dropout(DROUP_OUT))\n",
        "# second layer\n",
        "model1.add(LSTM(units=NUM_NEURONS, return_sequences = True))\n",
        "model1.add(Dropout(DROUP_OUT))\n",
        "# third layer\n",
        "model1.add(LSTM(units=NUM_NEURONS, return_sequences = True))\n",
        "model1.add(Dropout(DROUP_OUT))\n",
        "# fourth layer\n",
        "model1.add(LSTM(units=NUM_NEURONS))\n",
        "model1.add(Dropout(DROUP_OUT))\n",
        "# outut layer\n",
        "model1.add(Dense(forward_days))\n",
        "#train model\n",
        "model1.compile(loss='mean_squared_error',optimizer='adam')\n",
        "              \n",
        "              # compile\n",
        "              \n",
        "history1 =model1.fit(X_train, Y_train, epochs = EPOCHES, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbhHj-eYzgQd",
        "outputId": "ee846bb1-8b42-48de-f497-65b1c175ff02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 73 samples\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 1s 20ms/sample - loss: 0.1981\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 856us/sample - loss: 0.0608\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0978\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 879us/sample - loss: 0.0636\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 943us/sample - loss: 0.0604\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 902us/sample - loss: 0.0579\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 867us/sample - loss: 0.0518\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 937us/sample - loss: 0.0916\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 897us/sample - loss: 0.0497\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 902us/sample - loss: 0.0768\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0497\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 921us/sample - loss: 0.0386\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0435\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0558\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 944us/sample - loss: 0.0678\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 935us/sample - loss: 0.0515\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0448\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 913us/sample - loss: 0.0487\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 920us/sample - loss: 0.0447\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 918us/sample - loss: 0.0484\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0305\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 928us/sample - loss: 0.0759\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 953us/sample - loss: 0.0305\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 924us/sample - loss: 0.0417\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 910us/sample - loss: 0.0424\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0348\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0392\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 961us/sample - loss: 0.0305\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 934us/sample - loss: 0.0383\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 901us/sample - loss: 0.0583\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0474\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 907us/sample - loss: 0.0282\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 961us/sample - loss: 0.0395\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0328\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 896us/sample - loss: 0.0515\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 984us/sample - loss: 0.0259\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 916us/sample - loss: 0.0287\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0267\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 946us/sample - loss: 0.0331\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0438\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0272\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 972us/sample - loss: 0.0228\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0245\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0325\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 955us/sample - loss: 0.0182\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 936us/sample - loss: 0.0308\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 897us/sample - loss: 0.0405\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 924us/sample - loss: 0.0220\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 937us/sample - loss: 0.0232\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 937us/sample - loss: 0.0372\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 949us/sample - loss: 0.0212\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0255\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 953us/sample - loss: 0.0201\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0285\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 989us/sample - loss: 0.0208\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 996us/sample - loss: 0.0276\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 942us/sample - loss: 0.0300\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0350\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 964us/sample - loss: 0.0173\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 911us/sample - loss: 0.0176\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 960us/sample - loss: 0.0246\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0258\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0323\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 932us/sample - loss: 0.0194\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 954us/sample - loss: 0.0173\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0278\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 934us/sample - loss: 0.0245\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 987us/sample - loss: 0.0247\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0215\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0197\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 923us/sample - loss: 0.0210\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0191\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 952us/sample - loss: 0.0200\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 923us/sample - loss: 0.0172\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 954us/sample - loss: 0.0168\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 968us/sample - loss: 0.0300\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0153\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 978us/sample - loss: 0.0202\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 986us/sample - loss: 0.0299\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 963us/sample - loss: 0.0197\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 915us/sample - loss: 0.0189\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0254\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 930us/sample - loss: 0.0182\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 974us/sample - loss: 0.0180\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 941us/sample - loss: 0.0255\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0154\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 972us/sample - loss: 0.0168\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 910us/sample - loss: 0.0212\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 904us/sample - loss: 0.0323\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0193\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 969us/sample - loss: 0.0177\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 942us/sample - loss: 0.0181\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0172\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0193\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 932us/sample - loss: 0.0167\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0163\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 935us/sample - loss: 0.0179\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 946us/sample - loss: 0.0273\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 969us/sample - loss: 0.0346\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0179\n"
          ]
        }
      ],
      "source": [
        "# build GRU model\n",
        "model2 = Sequential()\n",
        "# first layer\n",
        "model2.add(GRU(units=NUM_NEURONS, return_sequences = True, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model2.add(Dropout(DROUP_OUT))\n",
        "# second layer\n",
        "model2.add(GRU(units=NUM_NEURONS, return_sequences = True))\n",
        "model2.add(Dropout(DROUP_OUT))\n",
        "# third layer\n",
        "model2.add(GRU(units=NUM_NEURONS, return_sequences = True))\n",
        "model2.add(Dropout(DROUP_OUT))\n",
        "# fourth layer\n",
        "model2.add(GRU(units=NUM_NEURONS))\n",
        "model2.add(Dropout(DROUP_OUT))\n",
        "# output layer\n",
        "model2.add(Dense(forward_days))\n",
        "#train model\n",
        "model2.compile(loss='mean_squared_error',optimizer='rmsprop')\n",
        "              \n",
        "              # compile\n",
        "              \n",
        "history2 =model2.fit(X_train, Y_train, epochs = EPOCHES, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kd1oEFRA6Y8"
      },
      "source": [
        "# Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtshSNba-jpU",
        "outputId": "67f28396-f948-4180-ed3c-dcc3960f02f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.7/dist-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.6)\n",
            "Train on 73 samples\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 1s 14ms/sample - loss: 0.1822\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 549us/sample - loss: 0.0640\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 549us/sample - loss: 0.0961\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 698us/sample - loss: 0.0787\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 597us/sample - loss: 0.0598\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 600us/sample - loss: 0.0594\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 661us/sample - loss: 0.0594\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 602us/sample - loss: 0.0503\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 707us/sample - loss: 0.0464\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 805us/sample - loss: 0.0609\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 576us/sample - loss: 0.0543\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 609us/sample - loss: 0.0489\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 593us/sample - loss: 0.0530\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 731us/sample - loss: 0.0544\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 646us/sample - loss: 0.0460\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 640us/sample - loss: 0.0494\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 616us/sample - loss: 0.0409\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 581us/sample - loss: 0.0436\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 592us/sample - loss: 0.0485\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 620us/sample - loss: 0.0432\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 559us/sample - loss: 0.0393\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 597us/sample - loss: 0.0463\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 654us/sample - loss: 0.0401\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 652us/sample - loss: 0.0472\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 638us/sample - loss: 0.0454\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 582us/sample - loss: 0.0428\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 590us/sample - loss: 0.0492\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 570us/sample - loss: 0.0441\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 563us/sample - loss: 0.0437\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 689us/sample - loss: 0.0453\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 694us/sample - loss: 0.0424\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 610us/sample - loss: 0.0312\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 641us/sample - loss: 0.0454\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 639us/sample - loss: 0.0396\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 585us/sample - loss: 0.0370\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 592us/sample - loss: 0.0358\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 632us/sample - loss: 0.0390\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 689us/sample - loss: 0.0329\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 574us/sample - loss: 0.0375\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 603us/sample - loss: 0.0388\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 623us/sample - loss: 0.0357\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 563us/sample - loss: 0.0344\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 605us/sample - loss: 0.0335\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 645us/sample - loss: 0.0302\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 634us/sample - loss: 0.0331\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 599us/sample - loss: 0.0385\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 769us/sample - loss: 0.0331\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 797us/sample - loss: 0.0366\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 634us/sample - loss: 0.0384\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 701us/sample - loss: 0.0338\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 585us/sample - loss: 0.0297\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 709us/sample - loss: 0.0275\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 637us/sample - loss: 0.0310\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 580us/sample - loss: 0.0328\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 572us/sample - loss: 0.0312\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 633us/sample - loss: 0.0311\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 580us/sample - loss: 0.0408\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 553us/sample - loss: 0.0309\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 867us/sample - loss: 0.0321\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 612us/sample - loss: 0.0291\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 618us/sample - loss: 0.0297\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 584us/sample - loss: 0.0300\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 574us/sample - loss: 0.0250\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 591us/sample - loss: 0.0247\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 597us/sample - loss: 0.0228\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 612us/sample - loss: 0.0279\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 595us/sample - loss: 0.0239\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 595us/sample - loss: 0.0262\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 643us/sample - loss: 0.0217\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 593us/sample - loss: 0.0224\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 578us/sample - loss: 0.0270\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 581us/sample - loss: 0.0230\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 789us/sample - loss: 0.0212\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 740us/sample - loss: 0.0228\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 700us/sample - loss: 0.0227\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 636us/sample - loss: 0.0217\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 656us/sample - loss: 0.0207\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 764us/sample - loss: 0.0201\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 669us/sample - loss: 0.0196\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 668us/sample - loss: 0.0190\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 601us/sample - loss: 0.0166\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 616us/sample - loss: 0.0173\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 576us/sample - loss: 0.0160\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 656us/sample - loss: 0.0160\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 616us/sample - loss: 0.0172\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 620us/sample - loss: 0.0182\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 623us/sample - loss: 0.0175\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 597us/sample - loss: 0.0152\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 691us/sample - loss: 0.0136\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 740us/sample - loss: 0.0169\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 658us/sample - loss: 0.0194\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 601us/sample - loss: 0.0191\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 708us/sample - loss: 0.0242\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 643us/sample - loss: 0.0178\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 569us/sample - loss: 0.0293\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 573us/sample - loss: 0.0161\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 586us/sample - loss: 0.0210\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 667us/sample - loss: 0.0188\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 573us/sample - loss: 0.0144\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 600us/sample - loss: 0.0154\n"
          ]
        }
      ],
      "source": [
        "# attention (+LSTM)\n",
        "%pip install keras-self-attention\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(LSTM(units=NUM_NEURONS, return_sequences = True, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model3.add(Dropout(DROUP_OUT))\n",
        "model3.add(SeqSelfAttention(attention_activation='sigmoid',attention_width=3, history_only=True, attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL))\n",
        "model3.add(LSTM(units=NUM_NEURONS))\n",
        "model3.add(Dropout(DROUP_OUT))\n",
        "model3.add(Dense(forward_days))\n",
        "model3.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history3 =model3.fit(X_train, Y_train, epochs = EPOCHES, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzrIP03Abrpb",
        "outputId": "7bdc03c0-2e81-4910-c87b-dfbbeb3841ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xm1=model1.predict(X_validation)\n",
        "Xm1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJK_UKUKzgOl",
        "outputId": "3d8bfdd9-f9f3-4298-b1d5-af2e3084d55c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xm2=model2.predict(X_validation)\n",
        "Xm2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhJrolcZFzp8",
        "outputId": "fa8d72b5-b4bf-4dc4-c110-3ea2a05f3bee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xm3=model3.predict(X_validation)\n",
        "Xm3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ef-OEENQR6X",
        "outputId": "adf2df88-078d-433d-bb80-eeac7eef3e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.30414674]\n",
            " [0.3239251 ]\n",
            " [0.3270585 ]\n",
            " [0.31582546]\n",
            " [0.27470827]\n",
            " [0.24513344]\n",
            " [0.23315614]\n",
            " [0.2519112 ]\n",
            " [0.28723434]]\n",
            "[[0.3205406 ]\n",
            " [0.21276852]\n",
            " [0.14849275]\n",
            " [0.15027365]\n",
            " [0.19846721]\n",
            " [0.23930892]\n",
            " [0.27147412]\n",
            " [0.2735144 ]\n",
            " [0.2511515 ]]\n",
            "[[0.3889637 ]\n",
            " [0.38021547]\n",
            " [0.3454618 ]\n",
            " [0.30505025]\n",
            " [0.2695878 ]\n",
            " [0.25908905]\n",
            " [0.26891118]\n",
            " [0.2950235 ]\n",
            " [0.3222078 ]]\n"
          ]
        }
      ],
      "source": [
        "print(Xm1)\n",
        "print(Xm2)\n",
        "print(Xm3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hJmVAsMYQcjw"
      },
      "outputs": [],
      "source": [
        "Y_validation = Y_validation.reshape(-1,1)\n",
        "m2_Y_validation = scaler.inverse_transform(Y_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_U-w8dTzgIA",
        "outputId": "1039a152-b0cb-4a04-8ea3-14acde46b082"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_validation.reshape(-1,1)\n",
        "Y_validation.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvYUWiUiRWYK",
        "outputId": "9f9f89bd-eb1d-4be5-cf12-091bcae7e4a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2634.560059],\n",
              "       [2639.399902],\n",
              "       [2666.939941],\n",
              "       [2669.909912],\n",
              "       [2648.050049],\n",
              "       [2654.800049],\n",
              "       [2635.669922],\n",
              "       [2629.72998 ],\n",
              "       [2663.419922]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m2_Y_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv9HZtA1zgCh",
        "outputId": "193d5890-dbf9-4def-9f26-9a21dfaede5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2669.7715]\n",
            " [2675.5442]\n",
            " [2676.4587]\n",
            " [2673.1802]\n",
            " [2661.179 ]\n",
            " [2652.547 ]\n",
            " [2649.0513]\n",
            " [2654.5254]\n",
            " [2664.8352]]\n",
            "[[2674.5562]\n",
            " [2643.1008]\n",
            " [2624.3406]\n",
            " [2624.8604]\n",
            " [2638.9268]\n",
            " [2650.847 ]\n",
            " [2660.235 ]\n",
            " [2660.8306]\n",
            " [2654.3035]]\n",
            "[[2694.5269]\n",
            " [2691.9736]\n",
            " [2681.83  ]\n",
            " [2670.035 ]\n",
            " [2659.6846]\n",
            " [2656.6204]\n",
            " [2659.4873]\n",
            " [2667.1084]\n",
            " [2675.0427]]\n"
          ]
        }
      ],
      "source": [
        "m1_prediction = scaler.inverse_transform(Xm1)\n",
        "m2_prediction = scaler.inverse_transform(Xm2)\n",
        "m3_prediction = scaler.inverse_transform(Xm3)\n",
        "\n",
        "print(m1_prediction)\n",
        "print(m2_prediction)\n",
        "print(m3_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrxlqrE5zf61",
        "outputId": "65faadcf-731e-4e44-d1a0-145d80fb50aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2634.560059],\n",
              "       [2639.399902],\n",
              "       [2666.939941],\n",
              "       [2669.909912],\n",
              "       [2648.050049],\n",
              "       [2654.800049],\n",
              "       [2635.669922],\n",
              "       [2629.72998 ],\n",
              "       [2663.419922]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m2_Y_validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujUEmUDg3xpT"
      },
      "source": [
        "# level 0 model 2 validation unscaled output => m2_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ug2yWVxEPwl"
      },
      "outputs": [],
      "source": [
        "# getting test data output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaShQLqTay7e",
        "outputId": "13b3425f-5ebe-41be-e8fa-3e5c446cb9b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xmt1=model1.predict(X_test)\n",
        "Xmt1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jstIRnd2EQUI",
        "outputId": "25c3e59f-ff09-4ba5-b729-f38df077900a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xmt2=model2.predict(X_test)\n",
        "Xmt2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvzovUD4HBBf",
        "outputId": "a7836472-f1b6-4d83-fac4-b87abdf1171c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xmt3=model3.predict(X_test)\n",
        "Xmt3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hipluEHDEQa7",
        "outputId": "300c0eaa-aa3b-4a1a-9f08-027ab77d2e8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9,)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_test.reshape(-1,1)\n",
        "Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "r4IvUdS4EQYO"
      },
      "outputs": [],
      "source": [
        "m1_x_test = scaler.inverse_transform(Xmt1)\n",
        "m2_x_test = scaler.inverse_transform(Xmt2)\n",
        "m3_x_test = scaler.inverse_transform(Xmt3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jyjCd0jR0oX",
        "outputId": "5bc1922b-8b55-4505-e2ad-37e8557bdbc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2697.4011],\n",
              "       [2701.308 ],\n",
              "       [2706.2556],\n",
              "       [2705.451 ],\n",
              "       [2700.9854],\n",
              "       [2697.285 ],\n",
              "       [2692.017 ],\n",
              "       [2693.0186],\n",
              "       [2691.9978]], dtype=float32)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m2_x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7AzgzxRR10e",
        "outputId": "3d3208e9-17cf-442d-f40a-c16cb547416d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2730.5303],\n",
              "       [2726.1597],\n",
              "       [2712.208 ],\n",
              "       [2697.4966],\n",
              "       [2697.891 ],\n",
              "       [2704.8904],\n",
              "       [2704.684 ],\n",
              "       [2706.3137],\n",
              "       [2698.5588]], dtype=float32)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m1_x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzzEorFRHcZ9",
        "outputId": "e8320ec9-d8c6-476c-9d2d-3c2fb77b7b27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2735.932 ],\n",
              "       [2731.5208],\n",
              "       [2724.3442],\n",
              "       [2718.6926],\n",
              "       [2720.848 ],\n",
              "       [2725.4446],\n",
              "       [2723.8516],\n",
              "       [2723.3909],\n",
              "       [2716.6282]], dtype=float32)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m3_x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kp2WeKC_EQQ7"
      },
      "outputs": [],
      "source": [
        "Y_test = Y_test.reshape(-1,1)\n",
        "m2_Y_test = scaler.inverse_transform(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zEYNWAoEQOA",
        "outputId": "da9aafd5-2b7b-4e5d-dcd7-f12c0e36f86e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2733.01001 ],\n",
              "       [2724.439941],\n",
              "       [2733.290039],\n",
              "       [2727.76001 ],\n",
              "       [2721.330078],\n",
              "       [2689.860107],\n",
              "       [2724.01001 ],\n",
              "       [2705.27002 ],\n",
              "       [2734.620117]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m2_Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evrpxWh3mlNm",
        "outputId": "5fffd61c-1851-47e4-be3a-f13fc3bb296b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "level 0 model 2 test MSE  721.2191672747989\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "level0_model2_test_mse = mean_squared_error(m2_x_test, m2_Y_test)\n",
        "print(\"level 0 model 2 test MSE \", level0_model2_test_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy_CCijaR7QS",
        "outputId": "06a5f1a2-5743-4c61-99bf-fcedf325770e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "level 0 model 1 test MSE  424.41383545185846\n"
          ]
        }
      ],
      "source": [
        "level0_model1_test_mse = mean_squared_error(m1_x_test, m2_Y_test)\n",
        "print(\"level 0 model 1 test MSE \", level0_model1_test_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq-ZixDlHmHR",
        "outputId": "1ac43e98-d8d1-40ce-aad1-1c3baee0e3d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "level 0 model 3 test MSE  237.72305994450335\n"
          ]
        }
      ],
      "source": [
        "level0_model3_test_mse = mean_squared_error(m3_x_test, m2_Y_test)\n",
        "print(\"level 0 model 3 test MSE \", level0_model3_test_mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LKkKkni6oT-"
      },
      "source": [
        "# now train level 1 model with level 0 models' output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD4ebszktkwC",
        "outputId": "5883c86f-b655-4b5a-e870-805219f7122d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.18350648],\n",
              "       [0.20008866],\n",
              "       [0.29444584],\n",
              "       [0.3046215 ],\n",
              "       [0.22972564],\n",
              "       [0.25285236],\n",
              "       [0.18730908],\n",
              "       [0.16695776],\n",
              "       [0.28238561]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9efU4r-G8Bl",
        "outputId": "b54294d5-9b60-43aa-e295-c5941a7ad96d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2634.560059],\n",
              "       [2639.399902],\n",
              "       [2666.939941],\n",
              "       [2669.909912],\n",
              "       [2648.050049],\n",
              "       [2654.800049],\n",
              "       [2635.669922],\n",
              "       [2629.72998 ],\n",
              "       [2663.419922]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m2_Y_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "F0uzCuUq6nCx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "model4 = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(3,)),\n",
        "    keras.layers.Dense(18, activation='relu'),\n",
        "    keras.layers.Dense(9, activation='relu'),\n",
        "    #keras.layers.Dense(4, activation='relu'),\n",
        "    # yucen: change from 2 to 3\n",
        "    keras.layers.Dense(3, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "LA6Ogib_6nLB"
      },
      "outputs": [],
      "source": [
        "model4.compile(optimizer='rmsprop', \n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "c5Hjh1WdTxh3"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "normalized_x_validation1 = scaler.fit_transform(m1_prediction)\n",
        "normalized_x_validation2 = scaler.fit_transform(m2_prediction)\n",
        "normalized_x_validation3 = scaler.fit_transform(m3_prediction)\n",
        "\n",
        "normalized_y_validation = scaler.fit_transform(m2_Y_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaY0FyBHVYBC",
        "outputId": "d8348b21-bdbf-4862-a4e6-52aa33f5595e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 3)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "level1_train_data=np.concatenate((normalized_x_validation1, normalized_x_validation2, normalized_x_validation3), axis=-1)\n",
        "level1_train_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH1yI_je8cN8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL2a6LmM6nQR",
        "outputId": "cec6263c-8784-40a6-f804-deb5edbb9128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 9 samples\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - 0s 17ms/sample - loss: 0.2818 - mean_absolute_error: 0.4121\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.2573 - mean_absolute_error: 0.3894\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2414 - mean_absolute_error: 0.3799\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2281 - mean_absolute_error: 0.3646\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.2127 - mean_absolute_error: 0.3622\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2034 - mean_absolute_error: 0.3584\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.1926 - mean_absolute_error: 0.3505\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1814 - mean_absolute_error: 0.3492\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1729 - mean_absolute_error: 0.3460\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.1648 - mean_absolute_error: 0.3419\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1556 - mean_absolute_error: 0.3384\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1400 - mean_absolute_error: 0.3216\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1216 - mean_absolute_error: 0.3101\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1144 - mean_absolute_error: 0.3094\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1066 - mean_absolute_error: 0.2983\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0996 - mean_absolute_error: 0.2895\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0979 - mean_absolute_error: 0.2872\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0912 - mean_absolute_error: 0.2756\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0914 - mean_absolute_error: 0.2779\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0874 - mean_absolute_error: 0.2682\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0865 - mean_absolute_error: 0.2701\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0830 - mean_absolute_error: 0.2662\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0840 - mean_absolute_error: 0.2685\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0794 - mean_absolute_error: 0.2578\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0781 - mean_absolute_error: 0.2550\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0812 - mean_absolute_error: 0.2594\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0763 - mean_absolute_error: 0.2539\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0744 - mean_absolute_error: 0.2500\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0737 - mean_absolute_error: 0.2482\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0685 - mean_absolute_error: 0.2415\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0750 - mean_absolute_error: 0.2549\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0706 - mean_absolute_error: 0.2419\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0690 - mean_absolute_error: 0.2437\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0660 - mean_absolute_error: 0.2321\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0668 - mean_absolute_error: 0.2358\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0675 - mean_absolute_error: 0.2343\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0628 - mean_absolute_error: 0.2276\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0644 - mean_absolute_error: 0.2318\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0640 - mean_absolute_error: 0.2258\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0616 - mean_absolute_error: 0.2244\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0611 - mean_absolute_error: 0.2202\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0594 - mean_absolute_error: 0.2183\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0568 - mean_absolute_error: 0.2148\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0557 - mean_absolute_error: 0.2132\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0595 - mean_absolute_error: 0.2208\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0548 - mean_absolute_error: 0.2140\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0545 - mean_absolute_error: 0.2118\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0527 - mean_absolute_error: 0.2068\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0549 - mean_absolute_error: 0.2111\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0502 - mean_absolute_error: 0.2013\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0514 - mean_absolute_error: 0.2042\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.0492 - mean_absolute_error: 0.2000\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0495 - mean_absolute_error: 0.1977\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0503 - mean_absolute_error: 0.1985\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0477 - mean_absolute_error: 0.1992\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0463 - mean_absolute_error: 0.1912\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0471 - mean_absolute_error: 0.1951\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0477 - mean_absolute_error: 0.1930\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0441 - mean_absolute_error: 0.1856\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0443 - mean_absolute_error: 0.1875\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0448 - mean_absolute_error: 0.1833\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0446 - mean_absolute_error: 0.1880\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0433 - mean_absolute_error: 0.1895\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0416 - mean_absolute_error: 0.1801\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0416 - mean_absolute_error: 0.1804\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0411 - mean_absolute_error: 0.1737\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0402 - mean_absolute_error: 0.1740\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0407 - mean_absolute_error: 0.1750\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0404 - mean_absolute_error: 0.1744\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0386 - mean_absolute_error: 0.1718\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0357 - mean_absolute_error: 0.1664\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0384 - mean_absolute_error: 0.1690\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0367 - mean_absolute_error: 0.1720\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0373 - mean_absolute_error: 0.1653\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0370 - mean_absolute_error: 0.1670\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0336 - mean_absolute_error: 0.1552\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0351 - mean_absolute_error: 0.1614\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0337 - mean_absolute_error: 0.1557\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0338 - mean_absolute_error: 0.1537\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0337 - mean_absolute_error: 0.1530\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0331 - mean_absolute_error: 0.1532\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0345 - mean_absolute_error: 0.1578\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0324 - mean_absolute_error: 0.1517\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0340 - mean_absolute_error: 0.1525\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.0295 - mean_absolute_error: 0.1427\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0317 - mean_absolute_error: 0.1445\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0297 - mean_absolute_error: 0.1435\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0292 - mean_absolute_error: 0.1407\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0303 - mean_absolute_error: 0.1427\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0307 - mean_absolute_error: 0.1409\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0276 - mean_absolute_error: 0.1350\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0297 - mean_absolute_error: 0.1421\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0268 - mean_absolute_error: 0.1324\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0270 - mean_absolute_error: 0.1330\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0288 - mean_absolute_error: 0.1359\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0272 - mean_absolute_error: 0.1303\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0257 - mean_absolute_error: 0.1265\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0260 - mean_absolute_error: 0.1270\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0278 - mean_absolute_error: 0.1311\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0257 - mean_absolute_error: 0.1253\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79adb1cd90>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model4.fit(level1_train_data, normalized_y_validation, epochs=100, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "2hgymgqFUBUw"
      },
      "outputs": [],
      "source": [
        "normalized_x_test1 = scaler.fit_transform(m1_x_test)\n",
        "normalized_x_test2 = scaler.fit_transform(m2_x_test)\n",
        "normalized_x_test3 = scaler.fit_transform(m3_x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCMh9uXTVltn",
        "outputId": "ce2aba0e-0c99-4217-ae4a-6e279aa7b31f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 3)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "level1_test_data=np.concatenate((normalized_x_test1, normalized_x_test2, normalized_x_test3), axis=-1)\n",
        "level1_test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb78OZOoTheA",
        "outputId": "82923b6b-ebe2-4376-8f5b-34f38e0c0996"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xt4 =model4.predict(level1_test_data)\n",
        "Xt4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "zcuJLsCzUMEV"
      },
      "outputs": [],
      "source": [
        "predicted_stock_price = scaler.inverse_transform(Xt4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyibT7JKThmM",
        "outputId": "efdf8651-d3af-4c4c-e917-b3acb3bdbd92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Blending Ensemble MSE:  183.80227310243868\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(predicted_stock_price, m2_Y_test)\n",
        "print(\"Blending Ensemble MSE: \", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCSKUHMWW2iV",
        "outputId": "d2774b22-3f22-463d-cf92-15756ae30bf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2724.4119],\n",
              "       [2726.4148],\n",
              "       [2721.1138],\n",
              "       [2719.3037],\n",
              "       [2718.6453],\n",
              "       [2720.253 ],\n",
              "       [2723.203 ],\n",
              "       [2723.593 ],\n",
              "       [2725.17  ]], dtype=float32)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_stock_price"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FCKRmFuh-QIV"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "6c1938672b876ecbef750c1b2d08c409a1f3bf3017e47b483b60275345a7166b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
