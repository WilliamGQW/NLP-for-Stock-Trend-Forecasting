{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cite from Xinyi6\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../data/us_financial_news_articles_2018_with_sentiment.csv\", index_col=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2 = pd.DataFrame(df2)\n",
    "n = df.shape[0]\n",
    "\n",
    "for i in range(0, n):\n",
    "    df2['published_date'][i] = df2['published_date'][i][0:10]\n",
    "    if i % 10000 == 0:\n",
    "\n",
    "        print(i)\n",
    "df2.to_csv('../data/sentiment.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62545503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['source_name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df2.groupby(['source_name']).size()\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped=df2.groupby(['source_name']).filter(lambda x: x=='wsj.com')\n",
    "# print(grouped)\n",
    "# type(df2['source_name'][0])\n",
    "dff1 = df2[(df2.source_name == 'wsj.com')]\n",
    "print(dff1.shape)\n",
    "dff2 = df2[(df2.source_name == 'cnbc.com')]\n",
    "print(dff2.shape)\n",
    "dff3 = df2[(df2.source_name == 'fortune.com')]\n",
    "print(dff3.shape)\n",
    "dff4 = df2[(df2.source_name == 'reuters.com')]\n",
    "print(dff4.shape)\n",
    "\n",
    "dff1.to_csv('../data/sentiment_wsj.csv')\n",
    "dff2.to_csv('../data/sentiment_cnbc.csv')\n",
    "dff3.to_csv('../data/sentiment_fortune.csv')\n",
    "dff4.to_csv('../data/sentiment_reuters.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c877d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_csv(\"../data/SP500.csv\")  # ,index_col=0)\n",
    "sp = pd.DataFrame(sp)\n",
    "sp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by day, mean\n",
    "dff1g = dff1.groupby(['published_date']).agg(['mean'])\n",
    "print(dff1g.shape)\n",
    "dff2g = dff2.groupby(['published_date']).agg(['mean'])\n",
    "print(dff2g.shape)\n",
    "dff3g = dff3.groupby(['published_date']).agg(['mean'])\n",
    "print(dff3g.shape)\n",
    "dff4g = dff4.groupby(['published_date']).agg(['mean'])\n",
    "print(dff4g.shape)\n",
    "\n",
    "dff1g.to_csv('../data/sentiment_wsj_groupday.csv')\n",
    "dff2g.to_csv('../data/sentiment_cnbc_groupday.csv')\n",
    "dff3g.to_csv('../data/sentiment_fortune_groupday.csv')\n",
    "dff4g.to_csv('../data/sentiment_reuters_groupday.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(\"../data/sentiment_wsj_groupday1.csv\")  # ,index_col=0)\n",
    "d2 = pd.read_csv(\"../data/sentiment_cnbc_groupday1.csv\")\n",
    "d3 = pd.read_csv(\"../data/sentiment_fortune_groupday1.csv\")\n",
    "d4 = pd.read_csv(\"../data/sentiment_reuters_groupday1.csv\")\n",
    "d1 = pd.DataFrame(d1)\n",
    "d1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sp['Date'][0]))\n",
    "print(type(d1['published_date'][0]))\n",
    "print(sp.head())\n",
    "print(d1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = d1['published_date'][0]\n",
    "timeStruct = time.strptime(t, \"%Y/%m/%d\")\n",
    "strTime = time.strftime(\"%Y-%m-%d\", timeStruct)\n",
    "print(strTime)\n",
    "\n",
    "for i in range(0, d1.shape[0]):\n",
    "    t = d1['published_date'][i]\n",
    "    timeStruct = time.strptime(t, \"%Y/%m/%d\")\n",
    "    d1['published_date'][i] = time.strftime(\"%Y-%m-%d\", timeStruct)\n",
    "\n",
    "for i in range(0, d2.shape[0]):\n",
    "    t = d2['published_date'][i]\n",
    "    timeStruct = time.strptime(t, \"%Y/%m/%d\")\n",
    "    d2['published_date'][i] = time.strftime(\"%Y-%m-%d\", timeStruct)\n",
    "\n",
    "for i in range(0, d3.shape[0]):\n",
    "    t = d3['published_date'][i]\n",
    "    timeStruct = time.strptime(t, \"%Y/%m/%d\")\n",
    "    d3['published_date'][i] = time.strftime(\"%Y-%m-%d\", timeStruct)\n",
    "\n",
    "for i in range(0, d4.shape[0]):\n",
    "    t = d4['published_date'][i]\n",
    "    timeStruct = time.strptime(t, \"%Y/%m/%d\")\n",
    "    d4['published_date'][i] = time.strftime(\"%Y-%m-%d\", timeStruct)\n",
    "\n",
    "d1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a343db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/d1.npy', d1)\n",
    "np.save('../data/d2.npy', d2)\n",
    "np.save('../data/d3.npy', d3)\n",
    "np.save('../data/d4.npy', d4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013be7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda02b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_union_1 = pd.DataFrame(\n",
    "    columns=('idx', 'date', 'mean_compound', 'comp_flag'))\n",
    "sp_len = sp.shape[0]\n",
    "d_len = d1.shape[0]\n",
    "d = d1.copy()\n",
    "for i in range(0, sp_len):\n",
    "    idx = i\n",
    "    date = sp['Date'][i]\n",
    "    j = 0\n",
    "    t = 0\n",
    "    while j < d_len:\n",
    "        if sp['Date'][i] == d['published_date'][j]:\n",
    "            mean_compound = d['compound'][j]\n",
    "            comp_flag = 1\n",
    "            t = 1\n",
    "            break\n",
    "        j = j+1\n",
    "    if t == 0:\n",
    "        mean_compound = 0\n",
    "        comp_flag = 0\n",
    "\n",
    "    date_union_1 = date_union_1.append(pd.DataFrame({'idx': [idx],\n",
    "                                                    'date': [date],\n",
    "                                                     'mean_compound': [mean_compound],\n",
    "                                                     'comp_flag': [comp_flag]\n",
    "\n",
    "                                                     }), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3221848",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_union_2 = pd.DataFrame(\n",
    "    columns=('idx', 'date', 'mean_compound', 'comp_flag'))\n",
    "sp_len = sp.shape[0]\n",
    "d_len = d2.shape[0]\n",
    "d = d2.copy()\n",
    "for i in range(0, sp_len):\n",
    "    idx = i\n",
    "    date = sp['Date'][i]\n",
    "    j = 0\n",
    "    t = 0\n",
    "    while j < d_len:\n",
    "        if sp['Date'][i] == d['published_date'][j]:\n",
    "            mean_compound = d2['compound'][j]\n",
    "            comp_flag = 1\n",
    "            t = 1\n",
    "            break\n",
    "        j = j+1\n",
    "    if t == 0:\n",
    "        mean_compound = 0\n",
    "        comp_flag = 0\n",
    "\n",
    "    date_union_2 = date_union_2.append(pd.DataFrame({'idx': [idx],\n",
    "                                                    'date': [date],\n",
    "                                                     'mean_compound': [mean_compound],\n",
    "                                                     'comp_flag': [comp_flag]\n",
    "\n",
    "                                                     }), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_union_3 = pd.DataFrame(\n",
    "    columns=('idx', 'date', 'mean_compound', 'comp_flag'))\n",
    "sp_len = sp.shape[0]\n",
    "d_len = d3.shape[0]\n",
    "d = d3.copy()\n",
    "for i in range(0, sp_len):\n",
    "    idx = i\n",
    "    date = sp['Date'][i]\n",
    "    j = 0\n",
    "    t = 0\n",
    "    while j < d_len:\n",
    "        if sp['Date'][i] == d['published_date'][j]:\n",
    "            mean_compound = d['compound'][j]\n",
    "            comp_flag = 1\n",
    "            t = 1\n",
    "            break\n",
    "        j = j+1\n",
    "    if t == 0:\n",
    "        mean_compound = 0\n",
    "        comp_flag = 0\n",
    "\n",
    "    date_union_3 = date_union_3.append(pd.DataFrame({'idx': [idx],\n",
    "                                                    'date': [date],\n",
    "                                                     'mean_compound': [mean_compound],\n",
    "                                                     'comp_flag': [comp_flag]\n",
    "\n",
    "                                                     }), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a19380",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_union_4 = pd.DataFrame(\n",
    "    columns=('idx', 'date', 'mean_compound', 'comp_flag'))\n",
    "sp_len = sp.shape[0]\n",
    "d_len = d4.shape[0]\n",
    "d = d4.copy()\n",
    "for i in range(0, sp_len):\n",
    "    idx = i\n",
    "    date = sp['Date'][i]\n",
    "    j = 0\n",
    "    t = 0\n",
    "    while j < d_len:\n",
    "        if sp['Date'][i] == d['published_date'][j]:\n",
    "            mean_compound = d['compound'][j]\n",
    "            comp_flag = 1\n",
    "            t = 1\n",
    "            break\n",
    "        j = j+1\n",
    "    if t == 0:\n",
    "        mean_compound = 0\n",
    "        comp_flag = 0\n",
    "\n",
    "    date_union_4 = date_union_4.append(pd.DataFrame({'idx': [idx],\n",
    "                                                    'date': [date],\n",
    "                                                     'mean_compound': [mean_compound],\n",
    "                                                     'comp_flag': [comp_flag]\n",
    "\n",
    "                                                     }), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_union_1.to_csv('../data/date_union_1.csv')\n",
    "date_union_2.to_csv('../data/date_union_2.csv')\n",
    "date_union_3.to_csv(\"../data/date_union_3.csv\")\n",
    "date_union_4.to_csv('../data/sdate_union_4.csv')\n",
    "\n",
    "np.save('../data/date_union_1.npy', date_union_1)\n",
    "np.save('../data/date_union_2.npy', date_union_2)\n",
    "np.save('../data/date_union_3.npy', date_union_3)\n",
    "np.save('../data/date_union_4.npy', date_union_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d310a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_c = pd.DataFrame({'date': d1['published_date'],\n",
    "                     'wsj_mean_compound': d1['compound']})\n",
    "d2_c = pd.DataFrame({'date': d2['published_date'],\n",
    "                     'cnbc_mean_compound': d2['compound']})\n",
    "d3_c = pd.DataFrame({'date': d3['published_date'],\n",
    "                     'fortune_mean_compound': d3['compound']})\n",
    "d4_c = pd.DataFrame({'date': d4['published_date'],\n",
    "                     'reuters_mean_compound': d4['compound']})\n",
    "sp_p = pd.DataFrame({'date': sp['Date'],\n",
    "                     'Adj Close': sp['Adj Close']})\n",
    "\n",
    "df_sp_sentiment = d1_c.merge(d2_c, how='inner', on='date')\n",
    "df_sp_sentiment = df_sp_sentiment.merge(d3_c, how='inner', on='date')\n",
    "df_sp_sentiment = df_sp_sentiment.merge(d4_c, how='inner', on='date')\n",
    "df_sp_sentiment = df_sp_sentiment.merge(sp_p, how='inner', on='date')\n",
    "df_sp_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to .csv file\n",
    "# df_sp_sentiment.to_csv('../data/source_price.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "30855fca1de1a9e76fb191234c06e457444d085aee49bba65a45b68036adabaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
