{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQoSEyyE4pSB"
      },
      "source": [
        "# Group-15 NLP Stock Forecasting with OECD\n",
        "\n",
        "---\n",
        "\n",
        "- Hongye Li / hongyeli@usc.edu\n",
        "- Quanwei Gu / quanweig@usc.edu\n",
        "- Yucen Xie / yucenxie@usc.edu\n",
        "- Yunhao Han / yunhaoha@usc.edu\n",
        "- Zhiqi Lu / zhiqilu@usc.edu\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This project implements an ensemble deep learning model for stock prediction using S&P 500 Index data and news data collected from CNBC.com, Reuters.com, WSJ.com, and Fortune.com. These datasets were partially obtained from the research of Xinyi et al.(2019) and Yang et al.(2022).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gw8_Z-TJ87K",
        "outputId": "88086c8b-7184-42d5-c974-2cc183f291ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/Shareddrives/CS544-Group15/project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/Shareddrives/CS544-Group15/project'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K5bT3MnT4to",
        "outputId": "89310bfc-e4b5-4ae8-ce57-72147d8a5877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.7/dist-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# install packages and import libs\n",
        "%pip install keras-self-attention\n",
        "# %tensorflow_version 2.x\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from math import pi,sqrt,exp,pow,log\n",
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "import numpy as np\n",
        "from numpy import newaxis\n",
        "from numpy.linalg import det, inv\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.dates as mdates\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM, GRU, Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import statsmodels.api as sm \n",
        "import scipy.stats as scs\n",
        "import scipy.optimize as sco\n",
        "import scipy.interpolate as sci\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn import cluster\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import precision_recall_fscore_support, mean_squared_error, precision_score, recall_score, f1_score, classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cJmzr-I4tM7Z",
        "outputId": "fdc8e9ef-5cb7-4ef1-fd1a-1fae9c4441f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-aed85fc7-0003-4c0e-860e-ddf342feb8b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>CLI</th>\n",
              "      <th>BCI</th>\n",
              "      <th>CCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017/12/7</td>\n",
              "      <td>0.296</td>\n",
              "      <td>-0.1366</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2636.979980</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017/12/8</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.2423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2651.500000</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017/12/11</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2659.989990</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017/12/12</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2664.110107</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017/12/13</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2662.850098</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aed85fc7-0003-4c0e-860e-ddf342feb8b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aed85fc7-0003-4c0e-860e-ddf342feb8b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aed85fc7-0003-4c0e-860e-ddf342feb8b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         date  wsj_mean_compound  cnbc_mean_compound  fortune_mean_compound  \\\n",
              "0   2017/12/7              0.296             -0.1366                 0.0000   \n",
              "1   2017/12/8              0.000              0.0000                -0.2423   \n",
              "2  2017/12/11              0.000              0.0000                 0.0000   \n",
              "3  2017/12/12              0.000              0.0000                 0.0000   \n",
              "4  2017/12/13              0.000              0.0000                 0.0000   \n",
              "\n",
              "   reuters_mean_compound    Adj Close     CLI     BCI     CCI  \n",
              "0                    0.0  2636.979980  0.4484  1.3452  1.3407  \n",
              "1                    0.0  2651.500000  0.4484  1.3452  1.3407  \n",
              "2                    0.0  2659.989990  0.4484  1.3452  1.3407  \n",
              "3                    0.0  2664.110107  0.4484  1.3452  1.3407  \n",
              "4                    0.0  2662.850098  0.4484  1.3452  1.3407  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read data\n",
        "url = './data/source_price_sentiment_oecd.csv'\n",
        "stock_df = pd.read_csv(url)\n",
        "stock_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9gdRMoRIm2K"
      },
      "source": [
        "# Data Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li4Rosf9yaOU"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Our dataset contains 121 records/rows, where each one of them represents a trading day ranged from 2017-12-07 to 2018-06-01, and a total of 9 columns.\n",
        "\n",
        "- `date`: date of each trading day (excluding weekends)\n",
        "\n",
        "- `Adj Close` is the target value we want to predict, which represents the adjusted closing stock price for each trading day.\n",
        "\n",
        "- Columns with name ending with `compound` are sentiment scores generated using stock news gathered from different sources: WSJ, CNBC, Fortune and Reuters. These sentiment scores were computed using **Aware Dictionary and Sentiment Reasoner (VADER)**, which is a lexicon and rule-based model for general sen- timent analysis. VADER will give a compound score for each piece of news data, and the compound score is a metric that calculates the sum of all the lexicon ratings, which has a normalized value ranged in [-1, 1]. -1 means most extreme negative, 0 means neutral, and -1 means most extreme positive.\n",
        "\n",
        "- `CLI, BCI, CCI`: Consumer Confidence Index (CCI), the Business Confidence Index (BCI), and the Composite Leading Indicator (CLI) are 3 leading economic indicators, provided by [OECD](https://data.oecd.org/leadind/consumer-confidence-index-cci.htm#indicator-chart), which can generally represent the current heath and performance of the current market.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_kZo37XWl-j-",
        "outputId": "98c4961d-317d-4a44-de10-330346cdd9c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2bfa9f78-1b2a-40c3-8cbc-bf524f9b53c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>CLI</th>\n",
              "      <th>BCI</th>\n",
              "      <th>CCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017/12/7</td>\n",
              "      <td>0.296</td>\n",
              "      <td>-0.1366</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2636.979980</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017/12/8</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.2423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2651.500000</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017/12/11</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2659.989990</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017/12/12</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2664.110107</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017/12/13</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2662.850098</td>\n",
              "      <td>0.4484</td>\n",
              "      <td>1.3452</td>\n",
              "      <td>1.3407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bfa9f78-1b2a-40c3-8cbc-bf524f9b53c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bfa9f78-1b2a-40c3-8cbc-bf524f9b53c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bfa9f78-1b2a-40c3-8cbc-bf524f9b53c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         date  wsj_mean_compound  cnbc_mean_compound  fortune_mean_compound  \\\n",
              "0   2017/12/7              0.296             -0.1366                 0.0000   \n",
              "1   2017/12/8              0.000              0.0000                -0.2423   \n",
              "2  2017/12/11              0.000              0.0000                 0.0000   \n",
              "3  2017/12/12              0.000              0.0000                 0.0000   \n",
              "4  2017/12/13              0.000              0.0000                 0.0000   \n",
              "\n",
              "   reuters_mean_compound    Adj Close     CLI     BCI     CCI  \n",
              "0                    0.0  2636.979980  0.4484  1.3452  1.3407  \n",
              "1                    0.0  2651.500000  0.4484  1.3452  1.3407  \n",
              "2                    0.0  2659.989990  0.4484  1.3452  1.3407  \n",
              "3                    0.0  2664.110107  0.4484  1.3452  1.3407  \n",
              "4                    0.0  2662.850098  0.4484  1.3452  1.3407  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read data\n",
        "url = './data/source_price_sentiment_oecd.csv'\n",
        "stock_df = pd.read_csv(url)\n",
        "stock_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mYao5B8q9sNk",
        "outputId": "1d0f1211-820d-4914-848f-0f96ec011394"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e30539aa-d0e3-4502-877a-ab31b3779560\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>CLI</th>\n",
              "      <th>BCI</th>\n",
              "      <th>CCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>2018/5/25</td>\n",
              "      <td>0.030290</td>\n",
              "      <td>0.047433</td>\n",
              "      <td>0.011550</td>\n",
              "      <td>-0.025190</td>\n",
              "      <td>2721.330078</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>2018/5/29</td>\n",
              "      <td>-0.052796</td>\n",
              "      <td>0.070442</td>\n",
              "      <td>-0.025721</td>\n",
              "      <td>-0.035568</td>\n",
              "      <td>2689.860107</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>2018/5/30</td>\n",
              "      <td>-0.017367</td>\n",
              "      <td>0.038119</td>\n",
              "      <td>-0.076965</td>\n",
              "      <td>-0.063177</td>\n",
              "      <td>2724.010010</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>2018/5/31</td>\n",
              "      <td>-0.018636</td>\n",
              "      <td>0.057371</td>\n",
              "      <td>-0.064138</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>2705.270020</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>1.2187</td>\n",
              "      <td>1.5006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>2018/6/1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.061150</td>\n",
              "      <td>0.361200</td>\n",
              "      <td>-0.004489</td>\n",
              "      <td>2734.620117</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>1.3308</td>\n",
              "      <td>1.4417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e30539aa-d0e3-4502-877a-ab31b3779560')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e30539aa-d0e3-4502-877a-ab31b3779560 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e30539aa-d0e3-4502-877a-ab31b3779560');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          date  wsj_mean_compound  cnbc_mean_compound  fortune_mean_compound  \\\n",
              "116  2018/5/25           0.030290            0.047433               0.011550   \n",
              "117  2018/5/29          -0.052796            0.070442              -0.025721   \n",
              "118  2018/5/30          -0.017367            0.038119              -0.076965   \n",
              "119  2018/5/31          -0.018636            0.057371              -0.064138   \n",
              "120   2018/6/1           0.000000           -0.061150               0.361200   \n",
              "\n",
              "     reuters_mean_compound    Adj Close     CLI     BCI     CCI  \n",
              "116              -0.025190  2721.330078  0.7426  1.2187  1.5006  \n",
              "117              -0.035568  2689.860107  0.7426  1.2187  1.5006  \n",
              "118              -0.063177  2724.010010  0.7426  1.2187  1.5006  \n",
              "119              -0.025489  2705.270020  0.7426  1.2187  1.5006  \n",
              "120              -0.004489  2734.620117  0.7163  1.3308  1.4417  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stock_df.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dCX0Tbuzl-eU"
      },
      "outputs": [],
      "source": [
        "# use date as index\n",
        "stock_df.index = stock_df.date\n",
        "stock_df.drop('date', axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "MVnJG5oEl-ZM",
        "outputId": "5290a47e-6303-4886-c825-81ce2ad469fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-aa957cbe-67ba-43b0-89fe-cb6dd51cfb31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>CLI</th>\n",
              "      <th>BCI</th>\n",
              "      <th>CCI</th>\n",
              "      <th>close_price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017/12/7</th>\n",
              "      <td>0.296</td>\n",
              "      <td>-0.1366</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.191798</td>\n",
              "      <td>0.191798</td>\n",
              "      <td>0.191798</td>\n",
              "      <td>0.191798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/12/8</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.2423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.241546</td>\n",
              "      <td>0.241546</td>\n",
              "      <td>0.241546</td>\n",
              "      <td>0.241546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/12/11</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.270634</td>\n",
              "      <td>0.270634</td>\n",
              "      <td>0.270634</td>\n",
              "      <td>0.270634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/12/12</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.284750</td>\n",
              "      <td>0.284750</td>\n",
              "      <td>0.284750</td>\n",
              "      <td>0.284750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/12/13</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.280433</td>\n",
              "      <td>0.280433</td>\n",
              "      <td>0.280433</td>\n",
              "      <td>0.280433</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa957cbe-67ba-43b0-89fe-cb6dd51cfb31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa957cbe-67ba-43b0-89fe-cb6dd51cfb31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa957cbe-67ba-43b0-89fe-cb6dd51cfb31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            wsj_mean_compound  cnbc_mean_compound  fortune_mean_compound  \\\n",
              "date                                                                       \n",
              "2017/12/7               0.296             -0.1366                 0.0000   \n",
              "2017/12/8               0.000              0.0000                -0.2423   \n",
              "2017/12/11              0.000              0.0000                 0.0000   \n",
              "2017/12/12              0.000              0.0000                 0.0000   \n",
              "2017/12/13              0.000              0.0000                 0.0000   \n",
              "\n",
              "            reuters_mean_compound       CLI       BCI       CCI  close_price  \n",
              "date                                                                          \n",
              "2017/12/7                     0.0  0.191798  0.191798  0.191798     0.191798  \n",
              "2017/12/8                     0.0  0.241546  0.241546  0.241546     0.241546  \n",
              "2017/12/11                    0.0  0.270634  0.270634  0.270634     0.270634  \n",
              "2017/12/12                    0.0  0.284750  0.284750  0.284750     0.284750  \n",
              "2017/12/13                    0.0  0.280433  0.280433  0.280433     0.280433  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# nomalize adjust close stock price\n",
        "adjust_close = stock_df['Adj Close'].values\n",
        "CLI = stock_df['CLI'].values\n",
        "BCI = stock_df['BCI'].values\n",
        "CCI = stock_df['CCI'].values\n",
        "scaler = MinMaxScaler()\n",
        "scaled_adjust_close = scaler.fit_transform(adjust_close.reshape(-1, 1))\n",
        "new_stock_df = stock_df.drop(['Adj Close'], axis=1)\n",
        "new_stock_df['close_price'] = scaled_adjust_close\n",
        "\n",
        "new_stock_df['CLI'] = scaler.fit_transform(adjust_close.reshape(-1, 1))\n",
        "new_stock_df['BCI'] = scaler.fit_transform(adjust_close.reshape(-1, 1))\n",
        "new_stock_df['CCI'] = scaler.fit_transform(adjust_close.reshape(-1, 1))\n",
        "new_stock_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xEh2WY1y_7j",
        "outputId": "222413ca-3f00-4c70-d270-c0e92b3f1cdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 8)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_stock_df.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbNbcnZuHw-J"
      },
      "source": [
        "## Train-Validation-Test split\n",
        "\n",
        "Split data into 85% train-validation data and 15% test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "8kf1DwDPzADP"
      },
      "outputs": [],
      "source": [
        "# Train-test split. 85% train and 15% test\n",
        "train_validation_data, test_data = train_test_split(\n",
        "    new_stock_df, train_size=0.85, test_size=0.15, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7DF00uPzAYl",
        "outputId": "2cce0e65-9c4e-44ac-999e-c14da3cd3188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape:  (83, 8)\n",
            "Validation data shape:  (19, 8)\n",
            "Test data shape:  (19, 8)\n"
          ]
        }
      ],
      "source": [
        "validation_data = train_validation_data[83:]\n",
        "train_data = train_validation_data[:83]\n",
        "\n",
        "print(\"Train data shape: \", train_data.shape)\n",
        "print(\"Validation data shape: \", validation_data.shape)\n",
        "print(\"Test data shape: \", test_data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vIoWRhiL1FQ"
      },
      "source": [
        "## Time Series Data Processing\n",
        "\n",
        "Since the dataset we are working on uses date as index, and we need to deal with time series forecasting, which means we cannot use future data to make predictions on past data, we are using a sliding window with size=10 so that we can use the past 10 days to predict the next day.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "pUyc2PWvzgEt"
      },
      "outputs": [],
      "source": [
        "look_back = 10  # sliding window size\n",
        "forward_days = 1  # prediction size\n",
        "NUM_NEURONS = 50  # number of neurons per layer\n",
        "EPOCHES = 100\n",
        "BATCH_SIZE = 32\n",
        "DROUP_OUT = 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "vGNUGlwAzgKX"
      },
      "outputs": [],
      "source": [
        "# Get the data and splits in input X and output Y, by spliting in `n` past days as input X\n",
        "# and `m` coming days as Y.\n",
        "def getTimeSteps(data, look_back, forward_days, jump=1):\n",
        "    x, y = [], []\n",
        "    for i in range(0, len(data) - look_back, jump):\n",
        "        x.append(data[i:(i+look_back)])\n",
        "        y.append(data[(i+look_back):(i+look_back+forward_days)])\n",
        "    return np.array(x), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GlguqaLLzgSE"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = getTimeSteps(train_data.to_numpy(), look_back, forward_days)\n",
        "x_validation, y_validation = getTimeSteps(\n",
        "    validation_data.to_numpy(), look_back, forward_days)\n",
        "x_test, y_test = getTimeSteps(test_data.to_numpy(), look_back, forward_days)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCqJlq6HzgVx",
        "outputId": "56a13c12-7fe6-42c9-dcb9-f0a5143c0236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train shape:  (73,)\n",
            "y_validation shape:  (9,)\n",
            "y_test shape:  (9,)\n"
          ]
        }
      ],
      "source": [
        "# extract only the close_price column as Y\n",
        "y_train = y_train[:, 0, -1]\n",
        "y_validation = y_validation[:, 0, -1]\n",
        "y_test = y_test[:, 0, -1]\n",
        "\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"y_validation shape: \", y_validation.shape)\n",
        "print(\"y_test shape: \", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz8Rg6ecVYJa"
      },
      "source": [
        "# Level-1 Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCKRmFuh-QIV"
      },
      "source": [
        "## LSTM model\n",
        "\n",
        "Built a LSTM model consists of four hidden layers, and each one contains 50 neurons. 0.2 drop-out layers were added between every two hidden layers. During each epoch, we computed the MSE and used Adam as optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcEen7hea_yL",
        "outputId": "885148c8-6407-4b95-be69-66debb04739f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 73 samples\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 1s 17ms/sample - loss: 0.2570 - mean_squared_error: 0.2570\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.1599 - mean_squared_error: 0.1599\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0712 - mean_squared_error: 0.0712\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0910 - mean_squared_error: 0.0910\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0694 - mean_squared_error: 0.0694\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0583 - mean_squared_error: 0.0583\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0692 - mean_squared_error: 0.0692\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0706 - mean_squared_error: 0.0706\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0630 - mean_squared_error: 0.0630\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0558 - mean_squared_error: 0.0558\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0592 - mean_squared_error: 0.0592\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0665 - mean_squared_error: 0.0665\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0535 - mean_squared_error: 0.0535\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0545 - mean_squared_error: 0.0545\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0506 - mean_squared_error: 0.0506\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0646 - mean_squared_error: 0.0646\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0606 - mean_squared_error: 0.0606\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0578 - mean_squared_error: 0.0578\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0524 - mean_squared_error: 0.0524\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0537 - mean_squared_error: 0.0537\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0542 - mean_squared_error: 0.0542\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0545 - mean_squared_error: 0.0545\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0598 - mean_squared_error: 0.0598\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0592 - mean_squared_error: 0.0592\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0586 - mean_squared_error: 0.0586\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0594 - mean_squared_error: 0.0594\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0484 - mean_squared_error: 0.0484\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0545 - mean_squared_error: 0.0545\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0475 - mean_squared_error: 0.0475\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0518 - mean_squared_error: 0.0518\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0524 - mean_squared_error: 0.0524\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0540 - mean_squared_error: 0.0540\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0533 - mean_squared_error: 0.0533\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0476 - mean_squared_error: 0.0476\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0530 - mean_squared_error: 0.0530\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0503 - mean_squared_error: 0.0503\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0500 - mean_squared_error: 0.0500\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0514 - mean_squared_error: 0.0514\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0498 - mean_squared_error: 0.0498\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0490 - mean_squared_error: 0.0490\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0447 - mean_squared_error: 0.0447\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0472 - mean_squared_error: 0.0472\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0433 - mean_squared_error: 0.0433\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0486 - mean_squared_error: 0.0486\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0412 - mean_squared_error: 0.0412\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0459 - mean_squared_error: 0.0459\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0381 - mean_squared_error: 0.0381\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0423 - mean_squared_error: 0.0423\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0375 - mean_squared_error: 0.0375\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0384 - mean_squared_error: 0.0384\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0422 - mean_squared_error: 0.0422\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0394 - mean_squared_error: 0.0394\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0332 - mean_squared_error: 0.0332\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0326 - mean_squared_error: 0.0326\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0309 - mean_squared_error: 0.0309\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0332 - mean_squared_error: 0.0332\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0319 - mean_squared_error: 0.0319\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0364 - mean_squared_error: 0.0364\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0307 - mean_squared_error: 0.0307\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0233 - mean_squared_error: 0.0233\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0286 - mean_squared_error: 0.0286\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0247 - mean_squared_error: 0.0247\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0253 - mean_squared_error: 0.0253\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0300 - mean_squared_error: 0.0300\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0272 - mean_squared_error: 0.0272\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0295 - mean_squared_error: 0.0295\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0203 - mean_squared_error: 0.0203\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0209 - mean_squared_error: 0.0209\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0210 - mean_squared_error: 0.0210\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0231 - mean_squared_error: 0.0231\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0271 - mean_squared_error: 0.0271\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0213 - mean_squared_error: 0.0213\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0217 - mean_squared_error: 0.0217\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0326 - mean_squared_error: 0.0326\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0195 - mean_squared_error: 0.0195\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0190 - mean_squared_error: 0.0190\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0208 - mean_squared_error: 0.0208\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0240 - mean_squared_error: 0.0240\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0176 - mean_squared_error: 0.0176\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0175 - mean_squared_error: 0.0175\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0193 - mean_squared_error: 0.0193\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0176 - mean_squared_error: 0.0176\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0187 - mean_squared_error: 0.0187\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0259 - mean_squared_error: 0.0259\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0223 - mean_squared_error: 0.0223\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0219 - mean_squared_error: 0.0219\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0188 - mean_squared_error: 0.0188\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0211 - mean_squared_error: 0.0211\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0170 - mean_squared_error: 0.0170\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0191 - mean_squared_error: 0.0191\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0145 - mean_squared_error: 0.0145\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0171 - mean_squared_error: 0.0171\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0213 - mean_squared_error: 0.0213\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0181 - mean_squared_error: 0.0181\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0178 - mean_squared_error: 0.0178\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0169 - mean_squared_error: 0.0169\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0199 - mean_squared_error: 0.0199\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0195 - mean_squared_error: 0.0195\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0243 - mean_squared_error: 0.0243\n"
          ]
        }
      ],
      "source": [
        "# LSTM model\n",
        "model1 = Sequential()\n",
        "# layer 1\n",
        "model1.add(LSTM(units=NUM_NEURONS, return_sequences=True,\n",
        "           input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "model1.add(Dropout(DROUP_OUT))\n",
        "# layer 2\n",
        "model1.add(LSTM(units=NUM_NEURONS, return_sequences=True))\n",
        "model1.add(Dropout(DROUP_OUT))\n",
        "# layer 3\n",
        "model1.add(LSTM(units=NUM_NEURONS, return_sequences=True))\n",
        "model1.add(Dropout(DROUP_OUT))\n",
        "# layer 4\n",
        "model1.add(LSTM(units=NUM_NEURONS))\n",
        "model1.add(Dropout(DROUP_OUT))\n",
        "# output layer\n",
        "model1.add(Dense(forward_days))\n",
        "# train\n",
        "model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
        "history1 = model1.fit(x_train, y_train, epochs=EPOCHES, batch_size=BATCH_SIZE)\n",
        "# collect training loss\n",
        "model1_train_loss = history1.history['loss']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEoCVlPkVOVL"
      },
      "source": [
        "## GRU Model\n",
        "\n",
        "Built a GRU model with similar structure to the previous LSTM model. Used RMSprop as Optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbhHj-eYzgQd",
        "outputId": "a8295100-d12e-4fcc-9866-f237142dcd78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 73 samples\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 3s 44ms/sample - loss: 0.1348\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0443\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0538\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0485\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0412\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0498\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0723\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0393\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0353\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0512\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0424\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0359\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0412\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0399\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0370\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0330\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0345\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0468\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0366\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0360\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0301\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0339\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0292\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0321\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0275\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0433\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0335\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0224\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0257\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0206\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0559\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0441\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0234\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0301\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0263\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0212\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0297\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0293\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0249\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0215\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0251\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0197\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0327\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0304\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0174\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0193\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0354\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0227\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0200\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0198\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0190\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0197\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0230\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0264\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0225\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0232\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0305\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0240\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0171\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0185\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0183\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0244\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0273\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0258\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0251\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0252\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0315\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0176\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0198\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0217\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0190\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0198\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0232\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0193\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0235\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0148\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0167\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0201\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0165\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0173\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0278\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0167\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0238\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0196\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0225\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0194\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0201\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0167\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0180\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0249\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0192\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0246\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 3ms/sample - loss: 0.0178\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0237\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0217\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 2ms/sample - loss: 0.0174\n"
          ]
        }
      ],
      "source": [
        "# GRU model\n",
        "model2 = Sequential()\n",
        "# layer 1\n",
        "model2.add(GRU(units=NUM_NEURONS, return_sequences=True,\n",
        "           input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "model2.add(Dropout(DROUP_OUT))\n",
        "# layer 2\n",
        "model2.add(GRU(units=NUM_NEURONS, return_sequences=True))\n",
        "model2.add(Dropout(DROUP_OUT))\n",
        "# layer 3\n",
        "model2.add(GRU(units=NUM_NEURONS, return_sequences=True))\n",
        "model2.add(Dropout(DROUP_OUT))\n",
        "# layer 4\n",
        "model2.add(GRU(units=NUM_NEURONS))\n",
        "model2.add(Dropout(DROUP_OUT))\n",
        "# output layer\n",
        "model2.add(Dense(forward_days))\n",
        "# train\n",
        "model2.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
        "history2 = model2.fit(x_train, y_train, epochs=EPOCHES, batch_size=BATCH_SIZE)\n",
        "# collect training loss\n",
        "model2_train_loss = history2.history['loss']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kd1oEFRA6Y8"
      },
      "source": [
        "## Attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtshSNba-jpU",
        "outputId": "b32d07f6-11a1-4b7f-e825-7e970b6a5638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 73 samples\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 4s 53ms/sample - loss: 0.1786\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0667\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 947us/sample - loss: 0.0591\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 837us/sample - loss: 0.0895\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 813us/sample - loss: 0.0609\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 790us/sample - loss: 0.0546\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 756us/sample - loss: 0.0513\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 857us/sample - loss: 0.0554\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 762us/sample - loss: 0.0495\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 821us/sample - loss: 0.0518\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0476\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 981us/sample - loss: 0.0445\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 769us/sample - loss: 0.0525\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 684us/sample - loss: 0.0476\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 816us/sample - loss: 0.0396\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0448\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0462\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 857us/sample - loss: 0.0460\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 867us/sample - loss: 0.0469\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 858us/sample - loss: 0.0412\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 806us/sample - loss: 0.0455\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 934us/sample - loss: 0.0413\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0411\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0378\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 887us/sample - loss: 0.0378\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 925us/sample - loss: 0.0409\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 681us/sample - loss: 0.0453\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 822us/sample - loss: 0.0423\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 794us/sample - loss: 0.0366\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 835us/sample - loss: 0.0392\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 785us/sample - loss: 0.0374\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 768us/sample - loss: 0.0359\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 809us/sample - loss: 0.0445\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 786us/sample - loss: 0.0348\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 978us/sample - loss: 0.0333\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 779us/sample - loss: 0.0317\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 891us/sample - loss: 0.0297\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0333\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 765us/sample - loss: 0.0338\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0313\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 954us/sample - loss: 0.0303\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0243\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 810us/sample - loss: 0.0281\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 982us/sample - loss: 0.0307\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0268\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0265\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 988us/sample - loss: 0.0231\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 917us/sample - loss: 0.0276\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 944us/sample - loss: 0.0242\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0214\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 919us/sample - loss: 0.0275\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 945us/sample - loss: 0.0206\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 889us/sample - loss: 0.0299\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0184\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0238\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 739us/sample - loss: 0.0200\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 793us/sample - loss: 0.0190\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 893us/sample - loss: 0.0205\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 890us/sample - loss: 0.0203\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0213\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 754us/sample - loss: 0.0155\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 674us/sample - loss: 0.0211\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 976us/sample - loss: 0.0191\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 745us/sample - loss: 0.0180\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0188\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 725us/sample - loss: 0.0217\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 806us/sample - loss: 0.0169\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0170\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 1ms/sample - loss: 0.0149\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 990us/sample - loss: 0.0175\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 775us/sample - loss: 0.0176\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 911us/sample - loss: 0.0189\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 983us/sample - loss: 0.0172\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 625us/sample - loss: 0.0164\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 543us/sample - loss: 0.0167\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 545us/sample - loss: 0.0188\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 557us/sample - loss: 0.0170\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 631us/sample - loss: 0.0192\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 583us/sample - loss: 0.0203\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 562us/sample - loss: 0.0172\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 612us/sample - loss: 0.0146\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 601us/sample - loss: 0.0170\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 539us/sample - loss: 0.0165\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 599us/sample - loss: 0.0161\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 575us/sample - loss: 0.0137\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 554us/sample - loss: 0.0170\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 592us/sample - loss: 0.0158\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 627us/sample - loss: 0.0149\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 563us/sample - loss: 0.0148\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 670us/sample - loss: 0.0161\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 550us/sample - loss: 0.0167\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 600us/sample - loss: 0.0126\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 573us/sample - loss: 0.0151\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 702us/sample - loss: 0.0158\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 599us/sample - loss: 0.0137\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 566us/sample - loss: 0.0166\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 565us/sample - loss: 0.0159\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 605us/sample - loss: 0.0123\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 677us/sample - loss: 0.0154\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 580us/sample - loss: 0.0163\n"
          ]
        }
      ],
      "source": [
        "# Attention model (with LSTM)\n",
        "model3 = Sequential()\n",
        "# layer 1\n",
        "model3.add(LSTM(units=NUM_NEURONS, return_sequences=True,\n",
        "           input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "model3.add(Dropout(DROUP_OUT))\n",
        "# layer 2\n",
        "model3.add(SeqSelfAttention(attention_activation='sigmoid', attention_width=3,\n",
        "           history_only=True, attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL))\n",
        "# layer 3\n",
        "model3.add(LSTM(units=NUM_NEURONS))\n",
        "model3.add(Dropout(DROUP_OUT))\n",
        "# output layer\n",
        "model3.add(Dense(forward_days))\n",
        "# train\n",
        "model3.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history3 = model3.fit(x_train, y_train, epochs=EPOCHES, batch_size=BATCH_SIZE)\n",
        "# collect training loss\n",
        "model3_train_loss = history3.history['loss']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XmRqmOLKKvX"
      },
      "source": [
        "## CNN_LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4obMLMXKJpP",
        "outputId": "0f9a5955-a9f8-4c91-c130-a46bec464534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 73 samples\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 0s 5ms/sample - loss: 0.2094 - mean_squared_error: 0.2094 - mean_absolute_error: 0.4013\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 260us/sample - loss: 0.0967 - mean_squared_error: 0.0967 - mean_absolute_error: 0.2646\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 334us/sample - loss: 0.0457 - mean_squared_error: 0.0457 - mean_absolute_error: 0.1772\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 272us/sample - loss: 0.0352 - mean_squared_error: 0.0352 - mean_absolute_error: 0.1325\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 276us/sample - loss: 0.0636 - mean_squared_error: 0.0636 - mean_absolute_error: 0.1887\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 288us/sample - loss: 0.0628 - mean_squared_error: 0.0628 - mean_absolute_error: 0.1828\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 307us/sample - loss: 0.0448 - mean_squared_error: 0.0448 - mean_absolute_error: 0.1467\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 313us/sample - loss: 0.0332 - mean_squared_error: 0.0332 - mean_absolute_error: 0.1379\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 350us/sample - loss: 0.0275 - mean_squared_error: 0.0275 - mean_absolute_error: 0.1318\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 325us/sample - loss: 0.0377 - mean_squared_error: 0.0377 - mean_absolute_error: 0.1598\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 304us/sample - loss: 0.0390 - mean_squared_error: 0.0390 - mean_absolute_error: 0.1624\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 287us/sample - loss: 0.0405 - mean_squared_error: 0.0405 - mean_absolute_error: 0.1682\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 312us/sample - loss: 0.0324 - mean_squared_error: 0.0324 - mean_absolute_error: 0.1452\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 289us/sample - loss: 0.0269 - mean_squared_error: 0.0269 - mean_absolute_error: 0.1277\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 306us/sample - loss: 0.0280 - mean_squared_error: 0.0280 - mean_absolute_error: 0.1285\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 317us/sample - loss: 0.0244 - mean_squared_error: 0.0244 - mean_absolute_error: 0.1180\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 294us/sample - loss: 0.0301 - mean_squared_error: 0.0301 - mean_absolute_error: 0.1295\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 273us/sample - loss: 0.0282 - mean_squared_error: 0.0282 - mean_absolute_error: 0.1240\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 289us/sample - loss: 0.0330 - mean_squared_error: 0.0330 - mean_absolute_error: 0.1415\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 287us/sample - loss: 0.0247 - mean_squared_error: 0.0247 - mean_absolute_error: 0.1257\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 296us/sample - loss: 0.0211 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1144\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 296us/sample - loss: 0.0217 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1156\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 315us/sample - loss: 0.0273 - mean_squared_error: 0.0273 - mean_absolute_error: 0.1223\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 292us/sample - loss: 0.0222 - mean_squared_error: 0.0222 - mean_absolute_error: 0.1221\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 296us/sample - loss: 0.0263 - mean_squared_error: 0.0263 - mean_absolute_error: 0.1253\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 307us/sample - loss: 0.0257 - mean_squared_error: 0.0257 - mean_absolute_error: 0.1217\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 278us/sample - loss: 0.0248 - mean_squared_error: 0.0248 - mean_absolute_error: 0.1177\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 335us/sample - loss: 0.0233 - mean_squared_error: 0.0233 - mean_absolute_error: 0.1151\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 322us/sample - loss: 0.0219 - mean_squared_error: 0.0219 - mean_absolute_error: 0.1148\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 338us/sample - loss: 0.0245 - mean_squared_error: 0.0245 - mean_absolute_error: 0.1161\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 323us/sample - loss: 0.0258 - mean_squared_error: 0.0258 - mean_absolute_error: 0.1226\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 297us/sample - loss: 0.0185 - mean_squared_error: 0.0185 - mean_absolute_error: 0.1052\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 285us/sample - loss: 0.0213 - mean_squared_error: 0.0213 - mean_absolute_error: 0.1060\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 333us/sample - loss: 0.0221 - mean_squared_error: 0.0221 - mean_absolute_error: 0.1184\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 289us/sample - loss: 0.0204 - mean_squared_error: 0.0204 - mean_absolute_error: 0.1067\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 285us/sample - loss: 0.0228 - mean_squared_error: 0.0228 - mean_absolute_error: 0.1107\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 302us/sample - loss: 0.0234 - mean_squared_error: 0.0234 - mean_absolute_error: 0.1127\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 289us/sample - loss: 0.0220 - mean_squared_error: 0.0220 - mean_absolute_error: 0.1117\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 324us/sample - loss: 0.0203 - mean_squared_error: 0.0203 - mean_absolute_error: 0.1088\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 287us/sample - loss: 0.0231 - mean_squared_error: 0.0231 - mean_absolute_error: 0.1159\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 365us/sample - loss: 0.0210 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1131\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 311us/sample - loss: 0.0262 - mean_squared_error: 0.0262 - mean_absolute_error: 0.1238\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 278us/sample - loss: 0.0214 - mean_squared_error: 0.0214 - mean_absolute_error: 0.1100\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 277us/sample - loss: 0.0207 - mean_squared_error: 0.0207 - mean_absolute_error: 0.1060\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 275us/sample - loss: 0.0208 - mean_squared_error: 0.0208 - mean_absolute_error: 0.1143\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 281us/sample - loss: 0.0163 - mean_squared_error: 0.0163 - mean_absolute_error: 0.0982\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 307us/sample - loss: 0.0218 - mean_squared_error: 0.0218 - mean_absolute_error: 0.1105\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 280us/sample - loss: 0.0219 - mean_squared_error: 0.0219 - mean_absolute_error: 0.1070\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 273us/sample - loss: 0.0192 - mean_squared_error: 0.0192 - mean_absolute_error: 0.1003\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 282us/sample - loss: 0.0217 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1003\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 323us/sample - loss: 0.0192 - mean_squared_error: 0.0192 - mean_absolute_error: 0.1039\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 265us/sample - loss: 0.0178 - mean_squared_error: 0.0178 - mean_absolute_error: 0.0980\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 269us/sample - loss: 0.0166 - mean_squared_error: 0.0166 - mean_absolute_error: 0.0947\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 246us/sample - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0948\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 303us/sample - loss: 0.0173 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1027\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 327us/sample - loss: 0.0176 - mean_squared_error: 0.0176 - mean_absolute_error: 0.0980\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 278us/sample - loss: 0.0181 - mean_squared_error: 0.0181 - mean_absolute_error: 0.1037\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 279us/sample - loss: 0.0156 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0973\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 299us/sample - loss: 0.0135 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0898\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 334us/sample - loss: 0.0187 - mean_squared_error: 0.0187 - mean_absolute_error: 0.1038\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 331us/sample - loss: 0.0167 - mean_squared_error: 0.0167 - mean_absolute_error: 0.0984\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 267us/sample - loss: 0.0164 - mean_squared_error: 0.0164 - mean_absolute_error: 0.0969\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 273us/sample - loss: 0.0166 - mean_squared_error: 0.0166 - mean_absolute_error: 0.0993\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 357us/sample - loss: 0.0149 - mean_squared_error: 0.0149 - mean_absolute_error: 0.0927\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 282us/sample - loss: 0.0153 - mean_squared_error: 0.0153 - mean_absolute_error: 0.0937\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 354us/sample - loss: 0.0140 - mean_squared_error: 0.0140 - mean_absolute_error: 0.0932\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 327us/sample - loss: 0.0181 - mean_squared_error: 0.0181 - mean_absolute_error: 0.1052\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 317us/sample - loss: 0.0179 - mean_squared_error: 0.0179 - mean_absolute_error: 0.1041\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 275us/sample - loss: 0.0166 - mean_squared_error: 0.0166 - mean_absolute_error: 0.1027\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 279us/sample - loss: 0.0162 - mean_squared_error: 0.0162 - mean_absolute_error: 0.0958\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 315us/sample - loss: 0.0149 - mean_squared_error: 0.0149 - mean_absolute_error: 0.0942\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 360us/sample - loss: 0.0138 - mean_squared_error: 0.0138 - mean_absolute_error: 0.0894\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 336us/sample - loss: 0.0137 - mean_squared_error: 0.0137 - mean_absolute_error: 0.0898\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 424us/sample - loss: 0.0162 - mean_squared_error: 0.0162 - mean_absolute_error: 0.1029\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 338us/sample - loss: 0.0173 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1052\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 289us/sample - loss: 0.0135 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0842\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 276us/sample - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.1009\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 296us/sample - loss: 0.0138 - mean_squared_error: 0.0138 - mean_absolute_error: 0.0953\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 273us/sample - loss: 0.0158 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0937\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 292us/sample - loss: 0.0133 - mean_squared_error: 0.0133 - mean_absolute_error: 0.0895\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 324us/sample - loss: 0.0170 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1040\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 288us/sample - loss: 0.0141 - mean_squared_error: 0.0141 - mean_absolute_error: 0.0963\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 301us/sample - loss: 0.0139 - mean_squared_error: 0.0139 - mean_absolute_error: 0.0920\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 292us/sample - loss: 0.0122 - mean_squared_error: 0.0122 - mean_absolute_error: 0.0901\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 344us/sample - loss: 0.0148 - mean_squared_error: 0.0148 - mean_absolute_error: 0.0928\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 299us/sample - loss: 0.0138 - mean_squared_error: 0.0138 - mean_absolute_error: 0.0904\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 316us/sample - loss: 0.0141 - mean_squared_error: 0.0141 - mean_absolute_error: 0.0906\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 313us/sample - loss: 0.0138 - mean_squared_error: 0.0138 - mean_absolute_error: 0.0904\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 284us/sample - loss: 0.0183 - mean_squared_error: 0.0183 - mean_absolute_error: 0.1040\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 282us/sample - loss: 0.0133 - mean_squared_error: 0.0133 - mean_absolute_error: 0.0885\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 310us/sample - loss: 0.0133 - mean_squared_error: 0.0133 - mean_absolute_error: 0.0887\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 354us/sample - loss: 0.0151 - mean_squared_error: 0.0151 - mean_absolute_error: 0.0959\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 298us/sample - loss: 0.0142 - mean_squared_error: 0.0142 - mean_absolute_error: 0.0849\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 291us/sample - loss: 0.0163 - mean_squared_error: 0.0163 - mean_absolute_error: 0.1012\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 283us/sample - loss: 0.0130 - mean_squared_error: 0.0130 - mean_absolute_error: 0.0873\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 311us/sample - loss: 0.0133 - mean_squared_error: 0.0133 - mean_absolute_error: 0.0866\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 330us/sample - loss: 0.0135 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0988\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 286us/sample - loss: 0.0140 - mean_squared_error: 0.0140 - mean_absolute_error: 0.0901\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 314us/sample - loss: 0.0146 - mean_squared_error: 0.0146 - mean_absolute_error: 0.0955\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 298us/sample - loss: 0.0116 - mean_squared_error: 0.0116 - mean_absolute_error: 0.0809\n"
          ]
        }
      ],
      "source": [
        "# build CNN_LSTM model\n",
        "model4 = Sequential()\n",
        "# conv layer\n",
        "model4.add(Conv1D(filters=32, kernel_size=1, activation='tanh',\n",
        "           padding='same', input_shape=(10, 8)))\n",
        "# maxpooling layer\n",
        "model4.add(MaxPooling1D(pool_size=1, padding='same'))\n",
        "# LSTM layer\n",
        "model4.add(LSTM(units=NUM_NEURONS, activation='tanh'))\n",
        "model4.add(Dropout(DROUP_OUT))\n",
        "# output layer\n",
        "model4.add(Dense(forward_days))\n",
        "# train model\n",
        "model4.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n",
        "history4 = model4.fit(x_train, y_train, epochs=EPOCHES,\n",
        "                      batch_size=64, verbose=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzrIP03Abrpb",
        "outputId": "47a4bb66-9e2d-4f65-f221-8535115375c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ],
      "source": [
        "# make predictions on Validation data\n",
        "y_hat_validation_1 = model1.predict(x_validation)\n",
        "y_hat_validation_2 = model2.predict(x_validation)\n",
        "y_hat_validation_3 = model3.predict(x_validation)\n",
        "y_hat_validation_4 = model4.predict(x_validation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv9HZtA1zgCh",
        "outputId": "9a32156e-6226-4d01-8b2f-dc4540d3b26b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.18350648],\n",
              "       [0.20008866],\n",
              "       [0.29444584],\n",
              "       [0.3046215 ],\n",
              "       [0.22972564],\n",
              "       [0.25285236],\n",
              "       [0.18730908],\n",
              "       [0.16695776],\n",
              "       [0.28238561]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Undo the scaling\n",
        "y_validation = y_validation.reshape(-1, 1)\n",
        "y_validation_unscaled = scaler.inverse_transform(y_validation)\n",
        "y_validation.reshape(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9eBNFLScVdn",
        "outputId": "d8ace59a-e1f9-4297-e87f-3bebf3adce98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2634.560059],\n",
              "       [2639.399902],\n",
              "       [2666.939941],\n",
              "       [2669.909912],\n",
              "       [2648.050049],\n",
              "       [2654.800049],\n",
              "       [2635.669922],\n",
              "       [2629.72998 ],\n",
              "       [2663.419922]])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_validation_unscaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "t2pPqJBqb9S8"
      },
      "outputs": [],
      "source": [
        "y_hat_validation_1 = scaler.inverse_transform(y_hat_validation_1)\n",
        "y_hat_validation_2 = scaler.inverse_transform(y_hat_validation_2)\n",
        "y_hat_validation_3 = scaler.inverse_transform(y_hat_validation_3)\n",
        "y_hat_validation_4 = scaler.inverse_transform(y_hat_validation_4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "QaShQLqTay7e"
      },
      "outputs": [],
      "source": [
        "# make predictions on test data use level-1 models repectively\n",
        "y_hat_test_1 = model1.predict(x_test)  # test LSTM\n",
        "y_hat_test_2 = model2.predict(x_test)  # test GRU\n",
        "y_hat_test_3 = model3.predict(x_test)  # test Attention\n",
        "y_hat_test_4 = model4.predict(x_test)  # test CNN\n",
        "\n",
        "y_hat_test_1 = scaler.inverse_transform(y_hat_test_1)\n",
        "y_hat_test_2 = scaler.inverse_transform(y_hat_test_2)\n",
        "y_hat_test_3 = scaler.inverse_transform(y_hat_test_3)\n",
        "y_hat_test_4 = scaler.inverse_transform(y_hat_test_4)\n",
        "\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "y_test = scaler.inverse_transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXSbkpmYZcHh",
        "outputId": "495d100d-f819-47cd-89a3-635fe5e2e509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2733.01001 ],\n",
              "       [2724.439941],\n",
              "       [2733.290039],\n",
              "       [2727.76001 ],\n",
              "       [2721.330078],\n",
              "       [2689.860107],\n",
              "       [2724.01001 ],\n",
              "       [2705.27002 ],\n",
              "       [2734.620117]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy_CCijaR7QS",
        "outputId": "77f97b1d-4035-47c6-f27c-636ba1e528fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM model test MSE:  255.34928606071404\n",
            "GRU model test MSE:  245.7714542284574\n",
            "Attention test MSE:  274.05758371243684\n",
            "CNN test MSE:  320.1301088658695\n"
          ]
        }
      ],
      "source": [
        "LSTM_mse = mean_squared_error(y_hat_test_1, y_test)\n",
        "GRU_mse = mean_squared_error(y_hat_test_2, y_test)\n",
        "Attention_mse = mean_squared_error(y_hat_test_3, y_test)\n",
        "CNN_mse = mean_squared_error(y_hat_test_4, y_test)\n",
        "print(\"LSTM model test MSE: \", LSTM_mse)\n",
        "print(\"GRU model test MSE: \", GRU_mse)\n",
        "print(\"Attention test MSE: \", Attention_mse)\n",
        "print(\"CNN test MSE: \", CNN_mse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LKkKkni6oT-"
      },
      "source": [
        "# Level-2 Blending Ensemble Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqtubJyv-5le"
      },
      "source": [
        "## Previous Work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5sdLENXC3hr"
      },
      "source": [
        "After we obtain the preditions of validation data for all 4 level-1 models, we combine them together into a new training dataset. This new dataset will be passed to the second level to train the meta-learner(level-2 model). We first implemented the previous LSTM_GRU ensemble model.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "XDyKcv0__DeA"
      },
      "outputs": [],
      "source": [
        "ensemble_model_prev = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(2,)),\n",
        "    keras.layers.Dense(18, activation='relu'),\n",
        "    keras.layers.Dense(9, activation='relu'),\n",
        "    keras.layers.Dense(2, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "bB7Daxyi_dmS"
      },
      "outputs": [],
      "source": [
        "ensemble_model_prev.compile(\n",
        "    optimizer='rmsprop', loss='mean_squared_error', metrics=['mae'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "QBDGN9dv_e6t"
      },
      "outputs": [],
      "source": [
        "scaler_prev = MinMaxScaler()\n",
        "scaled_y_hat_validation_1 = scaler_prev.fit_transform(y_hat_validation_1)\n",
        "scaled_y_hat_validation_2 = scaler_prev.fit_transform(y_hat_validation_2)\n",
        "scaled_y_validation = scaler_prev.fit_transform(y_validation_unscaled)\n",
        "\n",
        "# combine three validation predictions as new train dataset for the ensemble model\n",
        "train_data_level2_prev = np.concatenate(\n",
        "    (scaled_y_hat_validation_1, scaled_y_hat_validation_2), axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-dHPjsq_zu6",
        "outputId": "a62c6432-9631-4f6f-a4dd-6ed69357aa1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 9 samples\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - 0s 25ms/sample - loss: 0.3100 - mean_absolute_error: 0.4312\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2721 - mean_absolute_error: 0.4095\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2521 - mean_absolute_error: 0.4050\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2378 - mean_absolute_error: 0.3994\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2264 - mean_absolute_error: 0.3904\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2189 - mean_absolute_error: 0.3929\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2088 - mean_absolute_error: 0.3844\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1995 - mean_absolute_error: 0.3854\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1927 - mean_absolute_error: 0.3867\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.1893 - mean_absolute_error: 0.3842\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1855 - mean_absolute_error: 0.3821\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1826 - mean_absolute_error: 0.3796\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1785 - mean_absolute_error: 0.3796\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1732 - mean_absolute_error: 0.3752\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1706 - mean_absolute_error: 0.3736\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1672 - mean_absolute_error: 0.3733\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1662 - mean_absolute_error: 0.3727\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.1611 - mean_absolute_error: 0.3673\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.1601 - mean_absolute_error: 0.3679\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1591 - mean_absolute_error: 0.3663\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1572 - mean_absolute_error: 0.3636\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1540 - mean_absolute_error: 0.3608\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1557 - mean_absolute_error: 0.3641\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1524 - mean_absolute_error: 0.3604\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.1510 - mean_absolute_error: 0.3596\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1513 - mean_absolute_error: 0.3591\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1479 - mean_absolute_error: 0.3550\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.1480 - mean_absolute_error: 0.3564\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1449 - mean_absolute_error: 0.3523\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1446 - mean_absolute_error: 0.3514\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1424 - mean_absolute_error: 0.3497\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1438 - mean_absolute_error: 0.3515\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1415 - mean_absolute_error: 0.3479\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1395 - mean_absolute_error: 0.3454\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1393 - mean_absolute_error: 0.3441\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1368 - mean_absolute_error: 0.3432\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1353 - mean_absolute_error: 0.3401\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1361 - mean_absolute_error: 0.3423\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1345 - mean_absolute_error: 0.3409\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1325 - mean_absolute_error: 0.3384\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1302 - mean_absolute_error: 0.3350\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1300 - mean_absolute_error: 0.3341\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1286 - mean_absolute_error: 0.3327\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1290 - mean_absolute_error: 0.3340\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1249 - mean_absolute_error: 0.3284\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.1261 - mean_absolute_error: 0.3313\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1243 - mean_absolute_error: 0.3279\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1240 - mean_absolute_error: 0.3273\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1223 - mean_absolute_error: 0.3263\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1219 - mean_absolute_error: 0.3248\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1204 - mean_absolute_error: 0.3231\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.1184 - mean_absolute_error: 0.3206\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1159 - mean_absolute_error: 0.3169\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1153 - mean_absolute_error: 0.3165\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1145 - mean_absolute_error: 0.3161\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1123 - mean_absolute_error: 0.3129\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1123 - mean_absolute_error: 0.3130\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1128 - mean_absolute_error: 0.3134\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1111 - mean_absolute_error: 0.3114\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1082 - mean_absolute_error: 0.3067\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1092 - mean_absolute_error: 0.3077\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.1059 - mean_absolute_error: 0.3029\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1064 - mean_absolute_error: 0.3043\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1037 - mean_absolute_error: 0.2993\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1029 - mean_absolute_error: 0.2987\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1010 - mean_absolute_error: 0.2952\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1016 - mean_absolute_error: 0.2969\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0989 - mean_absolute_error: 0.2928\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0994 - mean_absolute_error: 0.2929\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0990 - mean_absolute_error: 0.2922\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0958 - mean_absolute_error: 0.2870\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.0950 - mean_absolute_error: 0.2839\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0924 - mean_absolute_error: 0.2820\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0919 - mean_absolute_error: 0.2806\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0905 - mean_absolute_error: 0.2766\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0885 - mean_absolute_error: 0.2739\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0898 - mean_absolute_error: 0.2753\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0873 - mean_absolute_error: 0.2707\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0844 - mean_absolute_error: 0.2674\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0846 - mean_absolute_error: 0.2678\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0846 - mean_absolute_error: 0.2661\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0816 - mean_absolute_error: 0.2610\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0825 - mean_absolute_error: 0.2614\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0793 - mean_absolute_error: 0.2562\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0783 - mean_absolute_error: 0.2542\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0772 - mean_absolute_error: 0.2518\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0778 - mean_absolute_error: 0.2525\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0766 - mean_absolute_error: 0.2496\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0760 - mean_absolute_error: 0.2491\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0750 - mean_absolute_error: 0.2459\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0739 - mean_absolute_error: 0.2446\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0721 - mean_absolute_error: 0.2398\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0726 - mean_absolute_error: 0.2412\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0724 - mean_absolute_error: 0.2398\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0705 - mean_absolute_error: 0.2370\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0692 - mean_absolute_error: 0.2334\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0695 - mean_absolute_error: 0.2343\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0692 - mean_absolute_error: 0.2322\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0678 - mean_absolute_error: 0.2298\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0680 - mean_absolute_error: 0.2294\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee8257ed50>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_model_prev.fit(train_data_level2_prev,\n",
        "                        scaled_y_validation, epochs=100, batch_size=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG3ZvmPa_5Sc"
      },
      "source": [
        "Next, we combine the test predictions generated by level-1 sub-models into a new test dataset. The meta-learner will make final predictions on this new test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Cc27aIP1_47K"
      },
      "outputs": [],
      "source": [
        "# combine test predictions generated by level1 sub-models\n",
        "scaled_y_hat_test_1 = scaler_prev.fit_transform(y_hat_test_1)\n",
        "scaled_y_hat_test_2 = scaler_prev.fit_transform(y_hat_test_2)\n",
        "\n",
        "test_data_level2_prev = np.concatenate(\n",
        "    (scaled_y_hat_test_1, scaled_y_hat_test_2), axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNeaJmVg_-eX",
        "outputId": "6f58f03a-716d-4349-c232-767c67c49578"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ],
      "source": [
        "y_hat_ensemble_prev = ensemble_model_prev.predict(test_data_level2_prev)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVlK02aNACVD",
        "outputId": "175c8d55-5120-4bf7-8fa7-12d6173a75db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2723.0427],\n",
              "       [2717.8904],\n",
              "       [2716.727 ],\n",
              "       [2717.7305],\n",
              "       [2717.7021],\n",
              "       [2717.534 ],\n",
              "       [2724.8596],\n",
              "       [2723.6362],\n",
              "       [2722.7146]], dtype=float32)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# undo the scaling to get the valid stock price\n",
        "ensemble_predicted_stock_price_prev = scaler_prev.inverse_transform(\n",
        "    y_hat_ensemble_prev)\n",
        "ensemble_predicted_stock_price_prev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2gwAq4OAFJ-",
        "outputId": "086190b5-0e4f-4f51-f3c3-75c84f894869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE of the Previous Blending Ensemble:  197.32792431986098\n"
          ]
        }
      ],
      "source": [
        "ensemble_mse_prev = mean_squared_error(\n",
        "    ensemble_predicted_stock_price_prev, y_test)\n",
        "print(\"MSE of the Previous Blending Ensemble: \", ensemble_mse_prev)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GXlPkCw-_qI"
      },
      "source": [
        "## Current Work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdSm_GJjq2yZ"
      },
      "source": [
        "After we obtain the preditions of validation data for all 4 level-1 models, we combine them together into a new training dataset. This new dataset will be passed to the second level to train the meta-learner(level-2 model). We then implemented our LSTM_GRU_Attension_CNNLSTM ensemble model.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "F0uzCuUq6nCx"
      },
      "outputs": [],
      "source": [
        "ensemble_model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(4,)),\n",
        "    keras.layers.Dense(18, activation='relu'),\n",
        "    keras.layers.Dense(9, activation='relu'),\n",
        "    keras.layers.Dense(4, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "LA6Ogib_6nLB"
      },
      "outputs": [],
      "source": [
        "ensemble_model.compile(optimizer='rmsprop',\n",
        "                       loss='mean_squared_error', metrics=['mae'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "c5Hjh1WdTxh3"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled_y_hat_validation_1 = scaler.fit_transform(y_hat_validation_1)\n",
        "scaled_y_hat_validation_2 = scaler.fit_transform(y_hat_validation_2)\n",
        "scaled_y_hat_validation_3 = scaler.fit_transform(y_hat_validation_3)\n",
        "scaled_y_hat_validation_4 = scaler.fit_transform(y_hat_validation_4)\n",
        "scaled_y_validation = scaler.fit_transform(y_validation_unscaled)\n",
        "\n",
        "# combine three validation predictions as new train dataset for the ensemble model\n",
        "train_data_level2 = np.concatenate((scaled_y_hat_validation_1, scaled_y_hat_validation_2,\n",
        "                                   scaled_y_hat_validation_3, scaled_y_hat_validation_4), axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL2a6LmM6nQR",
        "outputId": "16496a8c-5358-43e2-8df1-fb91a4e7b142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 9 samples\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - 0s 27ms/sample - loss: 0.3163 - mean_absolute_error: 0.4512\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2598 - mean_absolute_error: 0.3859\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.2281 - mean_absolute_error: 0.3565\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.2063 - mean_absolute_error: 0.3460\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1926 - mean_absolute_error: 0.3336\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1804 - mean_absolute_error: 0.3381\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1703 - mean_absolute_error: 0.3325\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1628 - mean_absolute_error: 0.3261\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1579 - mean_absolute_error: 0.3320\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1515 - mean_absolute_error: 0.3250\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1481 - mean_absolute_error: 0.3200\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1421 - mean_absolute_error: 0.3152\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1375 - mean_absolute_error: 0.3136\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1340 - mean_absolute_error: 0.3030\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1299 - mean_absolute_error: 0.3111\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1237 - mean_absolute_error: 0.3006\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1213 - mean_absolute_error: 0.3020\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1175 - mean_absolute_error: 0.2949\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1154 - mean_absolute_error: 0.2992\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1136 - mean_absolute_error: 0.2981\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1078 - mean_absolute_error: 0.2878\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1061 - mean_absolute_error: 0.2894\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.1015 - mean_absolute_error: 0.2878\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0982 - mean_absolute_error: 0.2821\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0950 - mean_absolute_error: 0.2783\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0928 - mean_absolute_error: 0.2752\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0906 - mean_absolute_error: 0.2718\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0898 - mean_absolute_error: 0.2698\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0878 - mean_absolute_error: 0.2645\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.0848 - mean_absolute_error: 0.2555\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0855 - mean_absolute_error: 0.2479\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0811 - mean_absolute_error: 0.2481\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0797 - mean_absolute_error: 0.2512\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0783 - mean_absolute_error: 0.2492\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0776 - mean_absolute_error: 0.2486\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0752 - mean_absolute_error: 0.2417\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0743 - mean_absolute_error: 0.2414\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0738 - mean_absolute_error: 0.2402\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0709 - mean_absolute_error: 0.2323\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.0696 - mean_absolute_error: 0.2297\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0684 - mean_absolute_error: 0.2265\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0693 - mean_absolute_error: 0.2294\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.0655 - mean_absolute_error: 0.2221\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0659 - mean_absolute_error: 0.2275\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0648 - mean_absolute_error: 0.2244\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0625 - mean_absolute_error: 0.2196\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0613 - mean_absolute_error: 0.2174\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0601 - mean_absolute_error: 0.2149\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0650 - mean_absolute_error: 0.2204\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0603 - mean_absolute_error: 0.2150\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0592 - mean_absolute_error: 0.2161\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0588 - mean_absolute_error: 0.2074\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0583 - mean_absolute_error: 0.2154\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0551 - mean_absolute_error: 0.2068\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0573 - mean_absolute_error: 0.2116\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0537 - mean_absolute_error: 0.2048\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0539 - mean_absolute_error: 0.2037\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0528 - mean_absolute_error: 0.2051\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0522 - mean_absolute_error: 0.2051\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0521 - mean_absolute_error: 0.2028\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0498 - mean_absolute_error: 0.2015\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0502 - mean_absolute_error: 0.2014\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0488 - mean_absolute_error: 0.1988\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0485 - mean_absolute_error: 0.1961\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0467 - mean_absolute_error: 0.1961\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0461 - mean_absolute_error: 0.1920\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0467 - mean_absolute_error: 0.1946\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0432 - mean_absolute_error: 0.1850\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0438 - mean_absolute_error: 0.1887\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0436 - mean_absolute_error: 0.1873\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.0408 - mean_absolute_error: 0.1803\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0414 - mean_absolute_error: 0.1796\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0397 - mean_absolute_error: 0.1790\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0389 - mean_absolute_error: 0.1747\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0398 - mean_absolute_error: 0.1777\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0406 - mean_absolute_error: 0.1766\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 0s 3ms/sample - loss: 0.0374 - mean_absolute_error: 0.1703\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0362 - mean_absolute_error: 0.1686\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0370 - mean_absolute_error: 0.1725\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0353 - mean_absolute_error: 0.1645\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 0s 1ms/sample - loss: 0.0351 - mean_absolute_error: 0.1675\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0351 - mean_absolute_error: 0.1668\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0330 - mean_absolute_error: 0.1599\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0348 - mean_absolute_error: 0.1634\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0342 - mean_absolute_error: 0.1627\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0339 - mean_absolute_error: 0.1542\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0334 - mean_absolute_error: 0.1561\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0315 - mean_absolute_error: 0.1585\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0318 - mean_absolute_error: 0.1574\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0306 - mean_absolute_error: 0.1533\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0292 - mean_absolute_error: 0.1496\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0312 - mean_absolute_error: 0.1540\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0294 - mean_absolute_error: 0.1496\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0279 - mean_absolute_error: 0.1463\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0285 - mean_absolute_error: 0.1453\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0303 - mean_absolute_error: 0.1500\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0294 - mean_absolute_error: 0.1469\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0271 - mean_absolute_error: 0.1390\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0266 - mean_absolute_error: 0.1390\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 0s 2ms/sample - loss: 0.0278 - mean_absolute_error: 0.1469\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee88c15a50>"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_model.fit(train_data_level2, scaled_y_validation,\n",
        "                   epochs=100, batch_size=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhhMkm9kspiN"
      },
      "source": [
        "Next, we combine the test predictions generated by level-1 sub-models into a new test dataset. The meta-learner will make final predictions on this new test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "2hgymgqFUBUw"
      },
      "outputs": [],
      "source": [
        "# combine test predictions generated by level1 sub-models\n",
        "scaled_y_hat_test_1 = scaler.fit_transform(y_hat_test_1)\n",
        "scaled_y_hat_test_2 = scaler.fit_transform(y_hat_test_2)\n",
        "scaled_y_hat_test_3 = scaler.fit_transform(y_hat_test_3)\n",
        "scaled_y_hat_test_4 = scaler.fit_transform(y_hat_test_4)\n",
        "\n",
        "test_data_level2 = np.concatenate(\n",
        "    (scaled_y_hat_test_1, scaled_y_hat_test_2, scaled_y_hat_test_3, scaled_y_hat_test_4), axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb78OZOoTheA",
        "outputId": "d160464d-4a37-4455-cc0d-da701946706e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ],
      "source": [
        "y_hat_ensemble = ensemble_model.predict(test_data_level2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcuJLsCzUMEV",
        "outputId": "ce252bd7-7acf-4a6e-a9ef-c56781b97929"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2715.9707],\n",
              "       [2715.9944],\n",
              "       [2716.1335],\n",
              "       [2716.1929],\n",
              "       [2716.2334],\n",
              "       [2716.1729],\n",
              "       [2725.7163],\n",
              "       [2724.1675],\n",
              "       [2729.2227]], dtype=float32)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# undo the scaling to get the valid stock price\n",
        "ensemble_predicted_stock_price = scaler.inverse_transform(y_hat_ensemble)\n",
        "ensemble_predicted_stock_price\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyibT7JKThmM",
        "outputId": "414e18c4-48e1-4fa9-aa5b-fe4a19102f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE of the Blending Ensemble:  210.81156766651128\n"
          ]
        }
      ],
      "source": [
        "ensemble_mse = mean_squared_error(ensemble_predicted_stock_price, y_test)\n",
        "print(\"MSE of the Blending Ensemble: \", ensemble_mse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KXpQQkLyfMn"
      },
      "source": [
        "# Result Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "avD8PQrtPqvd"
      },
      "outputs": [],
      "source": [
        "def format_score(y_tf, Y_tf, y, Y):\n",
        "    report = classification_report(y_tf, Y_tf, output_dict=True)\n",
        "    label = 'weighted avg'\n",
        "    mpa = round(float(1 - sum(abs(Y-y) / Y) / len(y)), 6)\n",
        "    mda = accuracy_score(y_tf, Y_tf)\n",
        "    return [mpa, report[label]['precision'], report[label]['recall'], report[label]['f1-score'], mda]\n",
        "\n",
        "\n",
        "m_trends = np.zeros((6, len(y_hat_test_1) - 1))\n",
        "actual_trends = np.zeros(len(y_hat_test_1) - 1)\n",
        "for i in range(1, len(y_hat_test_1)):\n",
        "    m_trends[0][i - 1] = y_hat_test_1[i] > y_hat_test_1[i - 1]\n",
        "    m_trends[1][i - 1] = y_hat_test_2[i] > y_hat_test_2[i - 1]\n",
        "    m_trends[2][i - 1] = y_hat_test_3[i] > y_hat_test_3[i - 1]\n",
        "    m_trends[3][i - 1] = y_hat_test_4[i] > y_hat_test_4[i - 1]\n",
        "    m_trends[4][i - 1] = ensemble_predicted_stock_price_prev[i] > ensemble_predicted_stock_price_prev[i - 1]\n",
        "    m_trends[5][i - 1] = ensemble_predicted_stock_price[i] > ensemble_predicted_stock_price[i - 1]\n",
        "    actual_trends[i - 1] = y_test[i] > y_test[i - 1]\n",
        "\n",
        "LSTM_scores = format_score(m_trends[0], actual_trends, y_hat_test_1, y_test)\n",
        "GRU_scores = format_score(m_trends[1], actual_trends, y_hat_test_2, y_test)\n",
        "Attention_scores = format_score(\n",
        "    m_trends[2], actual_trends, y_hat_test_3, y_test)\n",
        "CNN_scores = format_score(m_trends[3], actual_trends, y_hat_test_4, y_test)\n",
        "prev_ensemble_scores = format_score(\n",
        "    m_trends[4], actual_trends, ensemble_predicted_stock_price_prev, y_test)\n",
        "curr_ensemble_scores = format_score(\n",
        "    m_trends[5], actual_trends, ensemble_predicted_stock_price, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YnboMwLP8NI",
        "outputId": "9d318236-385c-4ac8-bea0-64d18f0be6e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 LSTM         GRU   Attention    CNN_LSTM  \\\n",
            "MSE        255.349286  245.771454  274.057584  320.130109   \n",
            "MPA          0.995351    0.995661    0.995687    0.994812   \n",
            "Precision    0.450000    0.500000    0.450000    0.450000   \n",
            "Recall       0.375000    0.500000    0.375000    0.375000   \n",
            "F1-score     0.409091    0.500000    0.409091    0.409091   \n",
            "MDA          0.375000    0.500000    0.375000    0.375000   \n",
            "\n",
            "           Previous Blending Ensemble  Current Blending Ensemble  \n",
            "MSE                        197.327924                 210.811568  \n",
            "MPA                          0.995682                   0.995434  \n",
            "Precision                    0.683333                   0.850000  \n",
            "Recall                       0.625000                   0.625000  \n",
            "F1-score                     0.645455                   0.642857  \n",
            "MDA                          0.625000                   0.625000  \n"
          ]
        }
      ],
      "source": [
        "# Table\n",
        "# MSE, MPA, Precision, Recall, F1-score, MDA\n",
        "data = [\n",
        "    [LSTM_mse, GRU_mse, Attention_mse, CNN_mse, ensemble_mse_prev, ensemble_mse],\n",
        "    [LSTM_scores[0], GRU_scores[0], Attention_scores[0], CNN_scores[0],\n",
        "        prev_ensemble_scores[0], curr_ensemble_scores[0]],\n",
        "    [LSTM_scores[1], GRU_scores[1], Attention_scores[1], CNN_scores[1],\n",
        "        prev_ensemble_scores[1], curr_ensemble_scores[1]],\n",
        "    [LSTM_scores[2], GRU_scores[2], Attention_scores[2], CNN_scores[2],\n",
        "        prev_ensemble_scores[2], curr_ensemble_scores[2]],\n",
        "    [LSTM_scores[3], GRU_scores[3], Attention_scores[3], CNN_scores[3],\n",
        "        prev_ensemble_scores[3], curr_ensemble_scores[3]],\n",
        "    [LSTM_scores[4], GRU_scores[4], Attention_scores[4], CNN_scores[4],\n",
        "        prev_ensemble_scores[4], curr_ensemble_scores[4]],\n",
        "\n",
        "]\n",
        "\n",
        "df_metrics = pd.DataFrame(data=data,\n",
        "                          index=['MSE', 'MPA', 'Precision',\n",
        "                                 'Recall', 'F1-score', 'MDA'],\n",
        "                          columns=[\"LSTM\", \"GRU\", \"Attention\", \"CNN_LSTM\", \"Previous Blending Ensemble\", \"Current Blending Ensemble\"])\n",
        "print(df_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "eidcJbqcQB9p",
        "outputId": "999eba3a-a5a5-4696-d4f5-8d428c4326f9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Charts\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "\n",
        "starting_time_idx = 95\n",
        "models = [\"LSTM\", \"GRU\", \"Attention\", \"CNN_LSTM\",\n",
        "          \"Previous Blending Ensemble\", \"Current Blending Ensemble\"]\n",
        "colors = ['tab:orange', 'tab:green', 'tab:cyan',\n",
        "          'tab:purple', 'tab:grey', 'tab:red']\n",
        "results = [y_hat_test_1, y_hat_test_2, y_hat_test_3, y_hat_test_4,\n",
        "           ensemble_predicted_stock_price_prev, ensemble_predicted_stock_price]\n",
        "\n",
        "# Actual Stock\n",
        "plt.plot(stock_df.index[starting_time_idx:], stock_df['Adj Close']\n",
        "         [starting_time_idx:], label='Actual Stock', c='tab:blue')\n",
        "\n",
        "# Prediction\n",
        "for i, r in enumerate(results):\n",
        "    plt.plot(test_data.index[-9:], r, linestyle='dashed',\n",
        "             label='%s' % (models[i]), c=colors[i])\n",
        "\n",
        "plt.xticks(stock_df.index[starting_time_idx::5],\n",
        "           stock_df.index[starting_time_idx::5])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_mi4TmJPnKv"
      },
      "source": [
        "# References\n",
        "\n",
        "1.  Xinyi L., Yinchuan L., Hongyang Y., Liuqing Y., Xi- aoyang L. 2019. DP-LSTM: Differential Privacy- inspired LSTM for Stock Prediction Using Financial News. ArXiv, abs/1912.10806\n",
        "2.  Yang L., Yi P. 2022. A novel ensemble deep learning model for stock prediction based on stock prices and news. International Journal of Data Science and Analytics, 13(2), 139-149.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FCKRmFuh-QIV",
        "UEoCVlPkVOVL",
        "4kd1oEFRA6Y8",
        "_XmRqmOLKKvX"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "30855fca1de1a9e76fb191234c06e457444d085aee49bba65a45b68036adabaf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
